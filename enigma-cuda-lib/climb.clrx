/*
 * climb.clrx - GCN assembler ClimbKernel version
 * Author: Mateusz Szpakowski
 */

/* predefined symbols:
 * TASK_SIZE - size of task in (ciphertext size)
 * TRIGRAMS_PITCH - trigrams pitch
 * SCRAMBLER_PITCH - scrambler pitch
 * SCRAMBLER_STRIDE - scrambler stride
 * SCORE_KINDS - score_kinds
 * TURNOVER_MODES - turnover_modes
 * SHORT_BIGRAMS - if nonzero then bigrams stored in ushort instead int
 * SHORT_TRIGRAMS - if nonzero then trigrams stored in ushort instead int
 */

.nomacrocase

ALPSIZE = 26
HALF_ALPSIZE = ALPSIZE>>1
ALPSIZE_TO2 = ALPSIZE*ALPSIZE
ALPSIZE_TO3 = ALPSIZE*ALPSIZE*ALPSIZE

UNROLL_SIZE = 16

.get_format BINFMT

AMDCL2_OR_GALLIUM = BINFMT==3 || BINFMT==1

ADDRBITS = 32
.iffmt amdcl2
    .if64
        ADDRBITS = 64
    .endif
.elseiffmt amd
    .if64
        ADDRBITS = 64
    .endif
.elseiffmt gallium
    ADDRBITS = 64
.endif

.iffmt gallium
.get_llvm_version LLVMVER
.endif

.ifgt TASK_SIZE-64
    .macro Barrier
        s_barrier
    .endm
.else
    .macro Barrier; .endm
.endif

.get_arch ARCH
GCN10 = 0
GCN11 = 1
GCN12 = 2
GCN14 = 3

.ifge ARCH - GCN12
        SMUL = 4
.else
        SMUL = 1
.endif

####
# allocator
####

__SREG_POOL0 = 0
__SREG_POOL1 = 0
__SREG_POOL2 = 0
__SREG_POOL3 = 0
__SREG_POOL_COUNT = ARCH>=GCN12 ? 102 : 104

__VREG_POOL0 = 0
__VREG_POOL1 = 0
__VREG_POOL2 = 0
__VREG_POOL3 = 0
__VREG_POOL_COUNT = 256

.macro Allocate1In64 Pool
    __PoolPos = 0
    .if (\Pool & (0xffffffff<<__PoolPos)) == (0xffffffff<<__PoolPos)
        __PoolPos = __PoolPos + 32
    .endif
    .if (\Pool & (0xffff<<__PoolPos)) == (0xffff<<__PoolPos)
        __PoolPos = __PoolPos + 16
    .endif
    .if (\Pool & (0xff<<__PoolPos)) == (0xff<<__PoolPos)
        __PoolPos = __PoolPos + 8
    .endif
    .if (\Pool & (0xf<<__PoolPos)) == (0xf<<__PoolPos)
        __PoolPos = __PoolPos + 4
    .endif
    .if (\Pool & (0x3<<__PoolPos)) == (0x3<<__PoolPos)
        __PoolPos = __PoolPos + 2
    .endif
    .if (\Pool & (1<<__PoolPos)) == (1<<__PoolPos)
        __PoolPos = __PoolPos + 1
    .endif
.endm

.macro Allocate1 Pool
    .if \Pool\()0 != -1  # if not full
        Allocate1In64 \Pool\()0
        \Pool\()0 = \Pool\()0 | (1<<__PoolPos)
    .elseif \Pool\()1 != -1  # if not full
        Allocate1In64 \Pool\()1
        \Pool\()1 = \Pool\()1 | (1<<__PoolPos)
        __PoolPos = __PoolPos + 64
    .elseif \Pool\()2 != -1  # if not full
        Allocate1In64 \Pool\()2
        \Pool\()2 = \Pool\()2 | (1<<__PoolPos)
        __PoolPos = __PoolPos + 128
    .elseif \Pool\()3 != -1  # if not full
        Allocate1In64 \Pool\()3
        \Pool\()3 = \Pool\()3 | (1<<__PoolPos)
        __PoolPos = __PoolPos + 192
    .else
        .error "Can't allocate register in \Pool"
    .endif
    .ifge __PoolPos - \Pool\()_COUNT
        .error "Can't allocate register in \Pool"
    .endif
.endm

.macro __EnableBits Pool, size
    __PoolBits = (1<<\size)-1
    .ifgt 64-__PoolPos
        \Pool\()0 = \Pool\()0 | (__PoolBits<<(__PoolPos))
        .ifgt __PoolPos+\size-64
            \Pool\()1 = \Pool\()1 | ((1<<(__PoolPos+\size-64))-1)
        .endif
    .elseifgt 128-__PoolPos
        \Pool\()1 = \Pool\()1 | (__PoolBits<<(__PoolPos-64))
        .ifgt __PoolPos+\size-128
            \Pool\()2 = \Pool\()2 | ((1<<(__PoolPos+\size-128))-1)
        .endif
    .elseifgt 192-__PoolPos
        \Pool\()2 = \Pool\()2 | (__PoolBits<<(__PoolPos-128))
        .ifgt __PoolPos+\size-192
            \Pool\()3 = \Pool\()3 | ((1<<(__PoolPos+\size-192))-1)
        .endif
    .else
        \Pool\()3 = \Pool\()3 | (__PoolBits<<(__PoolPos-192))
    .endif
.endm

.macro Allocate2 Pool
    __PoolPool0 = \Pool\()0|(\Pool\()0>>1)|(\Pool\()1<<63)
    __PoolPool1 = \Pool\()1|(\Pool\()1>>1)|(\Pool\()2<<63)
    __PoolPool2 = \Pool\()2|(\Pool\()2>>1)|(\Pool\()3<<63)
    __PoolPool3 = \Pool\()3|(\Pool\()3>>1)|(1<<63)
    __PoolPool_COUNT = \Pool\()_COUNT
    Allocate1 __PoolPool
    __EnableBits \Pool, 2
.endm

.macro Allocate2A Pool
    __PoolPool0 = \Pool\()0|(\Pool\()0>>1)|(\Pool\()1<<63) | 0xaaaaaaaaaaaaaaaa
    __PoolPool1 = \Pool\()1|(\Pool\()1>>1)|(\Pool\()2<<63) | 0xaaaaaaaaaaaaaaaa
    __PoolPool2 = \Pool\()2|(\Pool\()2>>1)|(\Pool\()3<<63) | 0xaaaaaaaaaaaaaaaa
    __PoolPool3 = \Pool\()3|(\Pool\()3>>1)|(1<<63) | 0xaaaaaaaaaaaaaaaa
    __PoolPool_COUNT = \Pool\()_COUNT
    Allocate1 __PoolPool
    __EnableBits \Pool, 2
.endm

.macro Allocate4 Pool
    __PoolPool0 = \Pool\()0|(\Pool\()0>>1)|(\Pool\()1<<63)
    __PoolPool1 = \Pool\()1|(\Pool\()1>>1)|(\Pool\()2<<63)
    __PoolPool2 = \Pool\()2|(\Pool\()2>>1)|(\Pool\()3<<63)
    __PoolPool3 = \Pool\()3|(\Pool\()3>>1)
    __PoolPool0 = __PoolPool0|(__PoolPool0>>2)|(__PoolPool1<<62)
    __PoolPool1 = __PoolPool1|(__PoolPool1>>2)|(__PoolPool2<<62)
    __PoolPool2 = __PoolPool2|(__PoolPool2>>2)|(__PoolPool3<<62)
    __PoolPool3 = __PoolPool3|(__PoolPool3>>2)|(7<<61)
    __PoolPool_COUNT = \Pool\()_COUNT
    Allocate1 __PoolPool
    __EnableBits \Pool, 4
.endm

.macro Allocate4A Pool
    __PoolPool0 = \Pool\()0|(\Pool\()0>>1)|(\Pool\()1<<63)
    __PoolPool1 = \Pool\()1|(\Pool\()1>>1)|(\Pool\()2<<63)
    __PoolPool2 = \Pool\()2|(\Pool\()2>>1)|(\Pool\()3<<63)
    __PoolPool3 = \Pool\()3|(\Pool\()3>>1)
    __PoolPool0 = __PoolPool0|(__PoolPool0>>2)|(__PoolPool1<<62) | 0xeeeeeeeeeeeeeeee
    __PoolPool1 = __PoolPool1|(__PoolPool1>>2)|(__PoolPool2<<62) | 0xeeeeeeeeeeeeeeee
    __PoolPool2 = __PoolPool2|(__PoolPool2>>2)|(__PoolPool3<<62) | 0xeeeeeeeeeeeeeeee
    __PoolPool3 = __PoolPool3|(__PoolPool3>>2)|(7<<61) | 0xeeeeeeeeeeeeeeee
    __PoolPool_COUNT = \Pool\()_COUNT
    Allocate1 __PoolPool
    __EnableBits \Pool, 4
.endm

.macro Free Pool, pos, size=1
    __PoolBits = (1<<\size)-1
    .ifgt 64-\pos
        \Pool\()0 = \Pool\()0 & ~(__PoolBits<<\pos)
        .ifgt \pos+\size-64
            \Pool\()1 = \Pool\()1 & ~((1<<(\pos+\size-64))-1)
        .endif
    .elseifgt 128-\pos
        \Pool\()1 = \Pool\()1 & ~(__PoolBits<<(\pos-64))
        .ifgt \pos+\size-128
            \Pool\()2 = \Pool\()2 & ~((1<<(\pos+\size-128))-1)
        .endif
    .elseifgt 192-\pos
        \Pool\()2 = \Pool\()2 & ~(__PoolBits<<(\pos-128))
        .ifgt \pos+\size-192
            \Pool\()3 = \Pool\()3 & ~((1<<(\pos+\size-192))-1)
        .endif
    .else
        \Pool\()3 = \Pool\()3 & ~(__PoolBits<<(\pos-192))
    .endif
.endm

.macro VRegAlloc1 name
    Allocate1 __VREG_POOL
    \name = %v[__PoolPos]
    \name\()__index = __PoolPos
    \name\()__size = 1
    \name\()__type = 1
.endm

.macro VRegAlloc1At name, pos
    __PoolPos = \pos
    __EnableBits __VREG_POOL, 1
    \name = %v[__PoolPos]
    \name\()__index = __PoolPos
    \name\()__size = 1
    \name\()__type = 1
.endm

.macro VRegAlloc2 name
    Allocate2 __VREG_POOL
    \name = %v[__PoolPos:__PoolPos+1]
    \name\()__index = __PoolPos
    \name\()__size = 2
    \name\()__type = 1
.endm

.macro VRegAlloc2At name, pos
    __PoolPos = \pos
    __EnableBits __VREG_POOL, 2
    \name = %v[__PoolPos:__PoolPos+1]
    \name\()__index = __PoolPos
    \name\()__size = 2
    \name\()__type = 1
.endm

.macro VRegAlloc4 name
    Allocate4 __VREG_POOL
    \name = %v[__PoolPos:__PoolPos+3]
    \name\()__index = __PoolPos
    \name\()__size = 4
    \name\()__type = 1
.endm

.macro VRegAlloc4At name, pos
    __PoolPos = \pos
    __EnableBits __VREG_POOL, 4
    \name = %v[__PoolPos:__PoolPos+3]
    \name\()__index = __PoolPos
    \name\()__size = 4
    \name\()__type = 1
.endm

.macro SRegAlloc1 name
    Allocate1 __SREG_POOL
    \name = %s[__PoolPos]
    \name\()__index = __PoolPos
    \name\()__size = 1
    \name\()__type = 0
.endm

.macro SRegAlloc1At name, pos
    __PoolPos = \pos
    __EnableBits __SREG_POOL, 1
    \name = %s[__PoolPos]
    \name\()__index = __PoolPos
    \name\()__size = 1
    \name\()__type = 0
.endm

.macro SRegAlloc2 name
    Allocate2 __SREG_POOL
    \name = %s[__PoolPos:__PoolPos+1]
    \name\()__index = __PoolPos
    \name\()__size = 2
    \name\()__type = 0
.endm

.macro SRegAlloc2A name
    Allocate2A __SREG_POOL
    \name = %s[__PoolPos:__PoolPos+1]
    \name\()__index = __PoolPos
    \name\()__size = 2
    \name\()__type = 0
.endm

.macro SRegAlloc2At name, pos
    __PoolPos = \pos
    __EnableBits __SREG_POOL, 2
    \name = %s[__PoolPos:__PoolPos+1]
    \name\()__index = __PoolPos
    \name\()__size = 2
    \name\()__type = 0
.endm

.macro SRegAlloc4 name
    Allocate4 __SREG_POOL
    \name = %s[__PoolPos:__PoolPos+3]
    \name\()__index = __PoolPos
    \name\()__size = 4
    \name\()__type = 0
.endm

.macro SRegAlloc4A name
    Allocate4A __SREG_POOL
    \name = %s[__PoolPos:__PoolPos+3]
    \name\()__index = __PoolPos
    \name\()__size = 4
    \name\()__type = 0
.endm

.macro SRegAlloc4At name, pos
    __PoolPos = \pos
    __EnableBits __SREG_POOL, 4
    \name = %s[__PoolPos:__PoolPos+3]
    \name\()__index = __PoolPos
    \name\()__size = 4
    \name\()__type = 0
.endm

.macro SavePool var
    \var\()0 = __SREG_POOL0
    \var\()1 = __SREG_POOL1
    \var\()2 = __SREG_POOL2
    \var\()3 = __SREG_POOL3
    \var\()4 = __VREG_POOL0
    \var\()5 = __VREG_POOL1
    \var\()6 = __VREG_POOL2
    \var\()7 = __VREG_POOL3
.endm

.macro RestorePool var
    __SREG_POOL0 = \var\()0
    __SREG_POOL1 = \var\()1
    __SREG_POOL2 = \var\()2
    __SREG_POOL3 = \var\()3
    __VREG_POOL0 = \var\()4
    __VREG_POOL1 = \var\()5
    __VREG_POOL2 = \var\()6
    __VREG_POOL3 = \var\()7
.endm

.macro ResetPool
    __SREG_POOL0 = 0
    __SREG_POOL1 = 0
    __SREG_POOL2 = 0
    __SREG_POOL3 = 0
    __VREG_POOL0 = 0
    __VREG_POOL1 = 0
    __VREG_POOL2 = 0
    __VREG_POOL3 = 0
.endm


.macro VRegFree name
    Free __VREG_POOL, \name\()__index, \name\()__size
.endm

.macro SRegFree name
    Free __SREG_POOL, \name\()__index, \name\()__size
.endm

.macro RegFree name
    .if \name\()__type==0
        Free __SREG_POOL, \name\()__index, \name\()__size
    .else
        Free __VREG_POOL, \name\()__index, \name\()__size
    .endif
.endm

.macro SMov32 a, ai, b, bi
    .if \a\()__type != \b\()__type || \a\()__index+\ai != \b\()__index+\bi
        s_mov_b32 \a[\ai], \b[\bi]
    .endif
.endm

.macro SMov64 a, ai, b, bi
    .if \a\()__type != \b\()__type || \a\()__index+\ai != \b\()__index+\bi
        s_mov_b64 \a[\ai:\ai+1], \b[\bi:\bi+1]
    .endif
.endm

.macro VMov32 a, ai, b, bi
    .if \a\()__type != \b\()__type || \a\()__index+\ai != \b\()__index+\bi
        v_mov_b32 \a[\ai], \b[\bi]
    .endif
.endm

.ifge ARCH-GCN14
    .macro VADD_U32 dest, cdest, src0, src1, mods:vararg
        v_add_co_u32 \dest, \cdest, \src0, \src1 \mods
    .endm
    .macro VADDC_U32 dest, cdest, src0, src1, csrc, mods:vararg
        v_addc_co_u32 \dest, \cdest, \src0, \src1, \csrc \mods
    .endm
    .macro VSUB_U32 dest, cdest, src0, src1, mods:vararg
        v_sub_co_u32 \dest, \cdest, \src0, \src1 \mods
    .endm
    .macro VSUBB_U32 dest, cdest, src0, src1, csrc, mods:vararg
        v_subb_co_u32 \dest, \cdest, \src0, \src1, \csrc \mods
    .endm
    .macro VSUBREV_U32 dest, cdest, src0, src1, mods:vararg
        v_subrev_co_u32 \dest, \cdest, \src0, \src1 \mods
    .endm
    .macro VSUBBREV_U32 dest, cdest, src0, src1, csrc, mods:vararg
        v_subbrev_co_u32 \dest, \cdest, \src0, \src1, \csrc \mods
    .endm
.else
    .macro VADD_U32 dest, cdest, src0, src1, mods:vararg
        v_add_u32 \dest, \cdest, \src0, \src1 \mods
    .endm
    .macro VADDC_U32 dest, cdest, src0, src1, csrc, mods:vararg
        v_addc_u32 \dest, \cdest, \src0, \src1, \csrc \mods
    .endm
    .macro VSUB_U32 dest, cdest, src0, src1, mods:vararg
        v_sub_u32 \dest, \cdest, \src0, \src1 \mods
    .endm
    .macro VSUBB_U32 dest, cdest, src0, src1, csrc, mods:vararg
        v_subb_u32 \dest, \cdest, \src0, \src1, \csrc \mods
    .endm
    .macro VSUBREV_U32 dest, cdest, src0, src1, mods:vararg
        v_subrev_u32 \dest, \cdest, \src0, \src1 \mods
    .endm
    .macro VSUBBREV_U32 dest, cdest, src0, src1, csrc, mods:vararg
        v_subbrev_u32 \dest, \cdest, \src0, \src1, \csrc \mods
    .endm
.endif

####
# debug stuff
####

.ifndef DEBUG
DEBUG = 0
.endif

.ifndef DEBUG_CLIMBINIT
DEBUG_CLIMBINIT = 0
.endif

#DEBUG = 3

.if DEBUG
WAVEFRONT_SIZE = (TASK_SIZE+63) & ~63
.macro DUMP_REG_START regsNum, type
    SavePool DebugOldPool
    SRegAlloc4A debugOut_res
    .ifeq \type # SRegType
        s_mov_b64 exec, 1
    .else
        s_mov_b64 exec, -1
    .endif
    .ifeq \type
        xdebugOut_arg = sdebugOut_arg
    .else
        xdebugOut_arg = vdebugOut_arg
    .endif
    .iffmt amdcl2 
        .if32
            SRegAlloc1 debugOut
            s_load_dword debugOut, argsPtr, xdebugOut_arg*SMUL
            s_mov_b64 debugOut_res[0:1], 0
        .else
            s_load_dwordx2 debugOut_res[0:1], argsPtr, xdebugOut_arg*SMUL
        .endif
        s_movk_i32 debugOut_res[2], 0xffff
        s_mov_b32 debugOut_res[3], 0x8027fac
    .elseiffmt amd
        .ifeq \type
            xdebugOut_uav = sdebugOut_uav
        .else
            xdebugOut_uav = vdebugOut_uav
        .endif
        s_load_dwordx4 debugOut_res, uavTablePtr, xdebugOut_uav*8*SMUL
        .if32
            SRegAlloc1 debugOut
            s_buffer_load_dword debugOut, constBuf1Res, xdebugOut_arg*SMUL
        .else
            SRegAlloc2A debugOut
            s_buffer_load_dwordx2 debugOut, constBuf1Res, xdebugOut_arg*SMUL
        .endif
    .endif
        s_waitcnt lgkmcnt(0)
        
    .ifeq \type # sregtype
        VRegAlloc1 gidv
        VRegAlloc1 tmpv
        v_mul_lo_u32 gidv, 4*\regsNum, gid
    .else
        VRegAlloc1 globalId
        s_mul_i32 gid, WAVEFRONT_SIZE, gid
        VADD_U32 globalId, vcc, gid, lid
        v_mul_lo_u32 globalId, 4*\regsNum, globalId
    .endif
    
    .ifeq \type # sregtype
        .iffmt amd
            .ifeq ADDRBITS-64
                s_add_u32 debugOut_res[0], debugOut_res[0], debugOut[0]
                s_addc_u32 debugOut_res[1], debugOut_res[1], debugOut[1]
            .endif
        .endif
    .else   # vregtype
        .iffmt amd
            .ifeq ADDRBITS-64
                s_add_u32 debugOut_res[0], debugOut_res[0], debugOut[0]
                s_addc_u32 debugOut_res[1], debugOut_res[1], debugOut[1]
            .endif
        .endif
    .endif
.endm
.macro DUMP_REG_SINGLE reg, offset,  type
    .ifeq \type # sregtype
            v_mov_b32 tmpv, \reg
        .iffmt amdcl2
            .if32
                buffer_store_dword tmpv, gidv, debugOut_res, debugOut offen offset:\offset
            .else
                buffer_store_dword tmpv, gidv, debugOut_res, 0 offen offset:\offset
            .endif
        .elseiffmt amd
            .if32
                buffer_store_dword tmpv, gidv, debugOut_res, debugOut offen offset:\offset
            .else
                buffer_store_dword tmpv, gidv, debugOut_res, 0 offen offset:\offset
            .endif
        .endif
    .else   # vregtype
        .iffmt amdcl2
            .if32
                buffer_store_dword \reg, globalId, debugOut_res, debugOut offen offset:\offset
            .else
                buffer_store_dword \reg, globalId, debugOut_res, 0 offen offset:\offset
            .endif
        .elseiffmt amd
            .if32
                buffer_store_dword \reg, globalId, debugOut_res, debugOut offen offset:\offset
            .else
                buffer_store_dword \reg, globalId, debugOut_res, 0 offen offset:\offset
            .endif
        .endif
    .endif
        s_waitcnt vmcnt(0)&expcnt(0)
.endm
.endif # DEBUG

.if DEBUG_CLIMBINIT
.macro DUMP_REG_START regsNum, type
    SavePool DebugOldPool
    SRegAlloc4A debugOut_res
    .ifeq \type
        .error "Unsupported"
    .else
        xdebugOut_arg = vdebugOut_arg
    .endif
    .iffmt amdcl2 
        .if32
            SRegAlloc1 debugOut
            s_load_dword debugOut, argsPtr, xdebugOut_arg*SMUL
            s_mov_b64 debugOut_res[0:1], 0
        .else
            s_load_dwordx2 debugOut_res[0:1], argsPtr, xdebugOut_arg*SMUL
        .endif
        s_movk_i32 debugOut_res[2], 0xffff
        s_mov_b32 debugOut_res[3], 0x8027fac
    .elseiffmt amd
        .ifne \type
            xdebugOut_uav = vdebugOut_uav
        .endif
        s_load_dwordx4 debugOut_res, uavTablePtr, xdebugOut_uav*8*SMUL
        .if32
            SRegAlloc1 debugOut
            s_buffer_load_dword debugOut, constBuf1Res, xdebugOut_arg*SMUL
        .else
            SRegAlloc2A debugOut
            s_buffer_load_dwordx2 debugOut, constBuf1Res, xdebugOut_arg*SMUL
        .endif
    .endif
        s_waitcnt lgkmcnt(0)
        
    .ifne \type # vregtype
        VRegAlloc1 globalId
        v_mul_lo_u32 globalId, 4*\regsNum, id
    .endif
    
    .ifne \type # vregtype
        .iffmt amd
            .ifeq ADDRBITS-64
                s_add_u32 debugOut_res[0], debugOut_res[0], debugOut[0]
                s_addc_u32 debugOut_res[1], debugOut_res[1], debugOut[1]
            .endif
        .endif
    .endif
.endm
.macro DUMP_REG_SINGLE reg, offset, type
    .ifne \type # vregtype
        .iffmt amdcl2
            .if32
                buffer_store_dword \reg, globalId, debugOut_res, debugOut offen offset:\offset
            .else
                buffer_store_dword \reg, globalId, debugOut_res, 0 offen offset:\offset
            .endif
        .elseiffmt amd
            .if32
                buffer_store_dword \reg, globalId, debugOut_res, debugOut offen offset:\offset
            .else
                buffer_store_dword \reg, globalId, debugOut_res, 0 offen offset:\offset
            .endif
        .endif
    .endif
        s_waitcnt vmcnt(0)&expcnt(0)
.endm
.endif

.if DEBUG|DEBUG_CLIMBINIT
.macro DUMP_REG_END
        s_endpgm
    RestorePool DebugOldPool
.endm

.macro DUMP_SREG reg
    DUMP_REG_START 1, 0
    DUMP_REG_SINGLE \reg, 0, 0
    DUMP_REG_END
.endm
.macro DUMP_VREG reg
    DUMP_REG_START 1, 1
    DUMP_REG_SINGLE \reg, 0, 1
    DUMP_REG_END
.endm

.macro DUMP_SREG2 reg0, reg1
    DUMP_REG_START 2, 0
    DUMP_REG_SINGLE \reg0, 0, 0
    DUMP_REG_SINGLE \reg1, 4, 0
    DUMP_REG_END
.endm
.macro DUMP_VREG2 reg0, reg1
    DUMP_REG_START 2, 1
    DUMP_REG_SINGLE \reg0, 0, 1
    DUMP_REG_SINGLE \reg1, 4, 1
    DUMP_REG_END
.endm

.macro DUMP_SREG3 reg0, reg1, reg2
    DUMP_REG_START 3, 0
    DUMP_REG_SINGLE \reg0, 0, 0
    DUMP_REG_SINGLE \reg1, 4, 0
    DUMP_REG_SINGLE \reg2, 8, 0
    DUMP_REG_END
.endm
.macro DUMP_VREG3 reg0, reg1, reg2
    DUMP_REG_START 3, 1
    DUMP_REG_SINGLE \reg0, 0, 1
    DUMP_REG_SINGLE \reg1, 4, 1
    DUMP_REG_SINGLE \reg2, 8, 1
    DUMP_REG_END
.endm
.endif  # DEBUG|DEBUG_CLIMBINIT

PRINT_INFO = 1

.ifndef DEBUG_PART
    DEBUG_PART = -1
.endif

.if PRINT_INFO
    .iffmt amdcl2
        .if32
            .print "AMD OpenCL 2.0 format 32-bit"
        .else
            .print "AMD OpenCL 2.0 format 64-bit"
        .endif
    .elseiffmt amd
        .if32
            .print "AMD OpenCL 1.2 format 32-bit"
        .else
            .print "AMD OpenCL 1.2 format 64-bit"
        .endif
    .elseiffmt gallium
        .ifge LLVMVER-40000
            .print "Gallium OpenCL1.1 format LLVM 4.0"
        .else
            .print "Gallium OpenCL1.1 format"
        .endif
    .endif
    .ifarch gcn1.0
        .print "GCN version: GCN 1.0"
    .elseifarch gcn1.1
        .print "GCN version: GCN 1.1"
    .elseifarch gcn1.2
        .print "GCN version: GCN 1.2"
    .elseifarch gcn1.4
        .print "GCN version: GCN 1.4"
    .endif
    
    .if DEBUG
        .ifdef DEBUG_PART
            .ifeq DEBUG_PART
                .print "ComputeScramblerIndex Test"
            .elseifeq DEBUG_PART-1
                .print "IcScore Test"
            .elseifeq DEBUG_PART-2
                .print "UniScore Test"
            .elseifeq DEBUG_PART-3
                .print "BiScore Test"
            .elseifeq DEBUG_PART-4
                .print "TriScore Test"
            .endif
        .endif
    .endif
.endif

.print "GCN Assembly Optimization 0.2r1"

####
# defs
####

Key.stru = 0
Key.stru.model = Key.stru+0
Key.stru.ukwnum = Key.stru+4
Key.stru.g_slot = Key.stru+8
Key.stru.l_slot = Key.stru+12
Key.stru.m_slot = Key.stru+16
Key.stru.t_slot = Key.stru+20

Key.sett = 24
Key.sett.g_ring = Key.sett+0
Key.sett.l_ring = Key.sett+4
Key.sett.m_ring = Key.sett+8
Key.sett.r_ring = Key.sett+12
Key.sett.g_mesg = Key.sett+16
Key.sett.l_mesg = Key.sett+20
Key.sett.m_mesg = Key.sett+24
Key.sett.r_mesg = Key.sett+28

rotNone = 0; rotI = 1; rotII = 2; rotIII = 3; rotIV = 4; rotV = 5; rotVI = 6
rotVII = 7; rotVIII = 8; rotBeta = 9; rotGamma = 10; ROTOR_TYPE_CNT = 11

refA = 0; refB = 1; refC = 2; refB_thin = 3; refC_thin = 4; REFLECTOR_TYPE_CNT = 5

# turnover modes
toBeforeMessage = 1; toDuringMessage = 2; toAfterMessage = 4

Wiring.reflectors = 0
Wiring.rotors = Wiring.reflectors + REFLECTOR_TYPE_CNT*ALPSIZE
Wiring.reverse_rotors = Wiring.rotors + ROTOR_TYPE_CNT*ALPSIZE
Wiring.notch_positions = Wiring.reverse_rotors + ROTOR_TYPE_CNT*ALPSIZE

NONE = -1

# score kinds
skIC = 1; skUnigram = 2; skBigram = 4; skTrigram = 8; skWords = 16

ResultSize = 8+28

.if DEBUG_PART==4 && (skTrigram&SCORE_KINDS)==0
    .error "TriScore Test requires enabled skTrigram"
.endif
.if DEBUG_PART==3 && (skBigram&SCORE_KINDS)==0
    .error "BiScore Test requires enabled skBigram"
.endif
.if DEBUG_PART==2 && (skUnigram&SCORE_KINDS)==0
    .error "UniScore Test requires enabled skUnigram"
.endif
.if DEBUG_PART==1 && (skIC&SCORE_KINDS)==0
    .error "ICScore Test requires enabled skIC"
.endif

    .macro SDivBy26 x, y
        VRegAlloc1 tmp1
        VRegAlloc1 tmp2
        s_add_u32 \y, \x, 1       # divide by 26
        v_mov_b32 tmp2, 10324440           # 1/26*(1<<28)
        v_mul_u32_u24 tmp1, \y, tmp2
        v_mul_hi_u32_u24 tmp2, \y, tmp2
        v_alignbit_b32 tmp1, tmp2, tmp1, 28
        v_readfirstlane_b32 \y, tmp1
        RegFree tmp1
        RegFree tmp2
    .endm
    
    .macro VDivBy26 x, y
        VRegAlloc1 tmp1
        VRegAlloc1 tmp2
        VADD_U32 \y, vcc, 1, \x    # divide by 26
        v_mov_b32 tmp2, 10324440           # 1/26*(1<<28)
        v_mul_u32_u24 tmp1, \y, tmp2
        v_mul_hi_u32_u24 tmp2, \y, tmp2
        v_alignbit_b32 \y, tmp2, tmp1, 28
        RegFree tmp1
        RegFree tmp2
    .endm
    
    .macro SSDivBy26 x, y
        VRegAlloc1 tmp1
        VRegAlloc1 tmp2
        v_mov_b32 tmp2, 5162220           # 1/26*(1<<27)
        v_mul_i32_i24 tmp1, \x, tmp2
        v_mul_hi_i32_i24 tmp2, \x, tmp2
        VADD_U32 tmp1, vcc, 2581110, tmp1
        VADDC_U32 tmp2, vcc, 0, tmp2, vcc
        v_alignbit_b32 tmp1, tmp2, tmp1, 27
        v_readfirstlane_b32 \y, tmp1
        RegFree tmp1
        RegFree tmp2
    .endm
    
    .macro SSDivByX x, y, const1, const2
        VRegAlloc1 tmp1
        VRegAlloc1 tmp2
        v_mov_b32 tmp2, \const1           # 1/26*(1<<27)
        v_mul_i32_i24 tmp1, \x, tmp2
        v_mul_hi_i32_i24 tmp2, \x, tmp2
        VADD_U32 tmp1, vcc, \const2, tmp1
        VADDC_U32 tmp2, vcc, 0, tmp2, vcc
        v_alignbit_b32 tmp1, tmp2, tmp1, 31
        v_readfirstlane_b32 \y, tmp1
        RegFree tmp1
        RegFree tmp2
    .endm
    
    .macro VSDivBy26 x, y
        VRegAlloc1 tmp1
        VRegAlloc1 tmp2
        v_mov_b32 tmp2, 5162220           # 1/26*(1<<27)
        v_mul_i32_i24 tmp1, \x, tmp2
        v_mul_hi_i32_i24 tmp2, \x, tmp2
        VADD_U32 tmp1, vcc, 2581110, tmp1
        VADDC_U32 tmp2, vcc, 0, tmp2, vcc
        v_alignbit_b32 \y, tmp2, tmp1, 27
        RegFree tmp1
        RegFree tmp2
    .endm
    
    .macro VSDivByX x, y, const1, const2
        VRegAlloc1 tmp1
        VRegAlloc1 tmp2
        v_mov_b32 tmp2, \const1           # 1/26*(1<<27)
        v_mul_i32_i24 tmp1, \x, tmp2
        v_mul_hi_i32_i24 tmp2, \x, tmp2
        VADD_U32 tmp1, vcc, \const2, tmp1
        VADDC_U32 tmp2, vcc, 0, tmp2, vcc
        v_alignbit_b32 \y, tmp2, tmp1, 31
        RegFree tmp1
        RegFree tmp2
    .endm
    
    # mod64(x): return (ALPSIZE * 2 + x) % ALPSIZE;
    .macro SMod26Fn x, y
        SRegAlloc1 tmp1
        s_add_u32 tmp1, \x, ALPSIZE*2
        s_mul_i32 \y, tmp1, 20165
        s_add_u32 \y, \y, 10000
        s_lshr_b32 \y, \y, 19
        s_mul_i32 \y, \y, ALPSIZE
        s_sub_u32 \y, tmp1, \y
        RegFree tmp1
    .endm
    
    .macro VMod26Fn x, y
        VRegAlloc1 tmp1
        VADD_U32 tmp1, vcc, ALPSIZE*2, \x
        v_mul_i32_i24 \y, 20165, tmp1
        VADD_U32 \y, vcc, 10000, \y
        v_lshrrev_b32 \y, 19, \y
        v_mul_i32_i24 \y, ALPSIZE, \y
        VSUB_U32 \y, vcc, tmp1, \y
        RegFree tmp1
    .endm
    
    .macro ComputeScramblerIndexFree
        RegFree l_period_const1
        RegFree l_period_const2
        RegFree l_phase
        RegFree m_period
        RegFree m_phase
        RegFree canInc_l_phase
    .endm

USE_LOCAL_IN_TRYSWAP = 1

####
# kernel
####

.scope

.kernel ClimbInitKernel
    .config
        .dims x
    .iffmt amdcl2
        .dx10clamp
        .ieeemode
        .useargs
        .usesetup
        .setupargs
        .arg d_wiring, "Wiring*", structure*, 1024, constant, const, rdonly
        .arg d_key, "Key*", structure*, 64, constant, const, rdonly
        .arg tasksNum, "int", int
        .arg tempClimbData, "ClimbTempEntry*", structure*, 64, global
    .if DEBUG_CLIMBINIT
        .arg vdebugOut, "uint*", char*, global,
    .endif
    SRegAlloc2At setupPtr, 4
    SRegAlloc2At argsPtr, 6
    .ifge ARCH-GCN14
        SRegAlloc1At gid, 10
    .else
        SRegAlloc1At gid, 8
    .endif
    .if32
        d_wiring_arg = 6
        d_key_arg = 7
        tasksNum_arg = 8
        tempClimbData_arg = 9
        .if DEBUG_CLIMBINIT
            vdebugOut_arg = 10
        .endif
    .else
        d_wiring_arg = 12
        d_key_arg = 14
        tasksNum_arg = 16
        tempClimbData_arg = 18
        .if DEBUG_CLIMBINIT
            vdebugOut_arg = 20
        .endif
    .endif
    .elseiffmt amd
        .uavid 11
        .uavprivate 0
        .printfid 9
        .privateid 8
        .cbid 10
        .userdata ptr_uav_table, 0, 2, 2
        .userdata imm_const_buffer, 0, 4, 4
        .userdata imm_const_buffer, 1, 8, 4
        .arg d_wiring, "Wiring*", structure*, 1024, constant, const
        .arg d_key, "Key*", structure*, 64, constant, const
        .arg tasksNum, "int", int
        .arg tempClimbData, "ClimbTempEntry*", structure*, 64, global
    .if DEBUG_CLIMBINIT
        .arg vdebugOut, "uint*", char*, global,
    .endif
        
        SRegAlloc2At uavTablePtr, 2
        SRegAlloc4At constBuf0Res, 4
        SRegAlloc4At constBuf1Res, 8
        SRegAlloc1At gid, 12
        
        d_wiring_arg = 0
        d_key_arg = 4
        tasksNum_arg = 8
        tempClimbData_arg = 12
    .if DEBUG_CLIMBINIT
        vdebugOut_arg = 16
    .endif
        
        uavStart = 12
        d_wiring_uav = uavStart+0
        d_key_uav = uavStart+1
        tempClimbData_uav = uavStart+2
    .if DEBUG_CLIMBINIT
        vdebugOut_uav = uavStart+3
    .endif
        
        sgprUserNum = 12
        freeSgprUser = 2
    
    .elseiffmt gallium
        .iflt LLVMVER-40000
            .dims xyz   # gallium set always three dimensions by Gallium
            .tgsize     # TG_SIZE_EN is always enabled by Gallium
        .endif
    .args
        .arg global, 8      # d_wiring
        .arg global, 8      # d_key
        .arg scalar, 4      # tasksNum
        .arg global, 8      # tempClimbData
    .if DEBUG_CLIMBINIT
        .arg scalar, 8      # vdebugOut
    .endif
        .arg griddim, 4
        .arg gridoffset, 4
    
        .ifge LLVMVER-40000
        
        .config
            .dims x
            .dx10clamp
            .ieeemode
            .default_hsa_features
            
            d_wiring_arg = 0
            d_key_arg = 2
            tasksNum_arg = 4
            tempClimbData_arg = 6
        .if DEBUG_CLIMBINIT
            vdebugOut_arg = 8     # vdebugOut
        .endif
        
            SRegAlloc2At argsPtr, 6
            SRegAlloc1At gid, 8
            
        .else # old LLVM
            
            d_wiring_arg = 9
            d_key_arg = 11
            tasksNum_arg = 13
            tempClimbData_arg = 15
        .if DEBUG_CLIMBINIT
            vdebugOut_arg = 17     # vdebugOut
        .endif
            
            SRegAlloc2At argsPtr, 0
            SRegAlloc1At gid, 4
        .endif
    .else
        .error "Unsupported binary format"
    .endif
    .text
.iffmt gallium
::ClimbInitKernel:
.ifge LLVMVER-40000
    .skip 256
.endif
.endif
    VRegAlloc1At id, 0
        # calculate gid
        s_lshl_b32 gid, gid, 8      # localsize - 256
        VADD_U32 id, vcc, gid, id
        # get tasksNum
        SRegAlloc1 tasksNum
    .if AMDCL2_OR_GALLIUM
        s_load_dword tasksNum, argsPtr, SMUL*tasksNum_arg
    .elseiffmt amd
        s_buffer_load_dword tasksNum, constBuf1Res, tasksNum_arg*SMUL
    .endif
        s_waitcnt lgkmcnt(0)
    
        v_cmpx_ge_u32 vcc, tasksNum, id
        s_cbranch_execz endOfClimbInit
        SRegAlloc2A tmpexec
        s_mov_b64 tmpexec, exec
        
        #########################################
        # main calculation
        
        /*
            //ring and rotor settings to be tried
            sett.g_ring = 0;
            sett.l_ring = 0;

            //depending on the grid size, ring positions 
            //either from grid index or fixed (from d_key)
            sett.m_ring = d_key->sett.m_ring;
            sett.r_ring = d_key->sett.r_ring;
        */
        
        SRegAlloc2A mr_ring
        # load m_ring, r_ring
    # load d_key struct
    .if AMDCL2_OR_GALLIUM
        .ifeq ADDRBITS-32
            SRegAlloc4A bufres
            SRegAlloc2 d_key
            s_load_dword d_key[0], argsPtr, SMUL*d_key_arg
            s_mov_b32 d_key[1], 0
            s_mov_b64 bufres[0:1], 0
            s_movk_i32 bufres[2], 0xffff
            s_mov_b32 bufres[3], 0x8027fac
        .else
            SRegAlloc4A d_key_res
            s_load_dwordx2 d_key_res[0:1], argsPtr, SMUL*d_key_arg
            s_movk_i32 d_key_res[2], 0xffff
            s_mov_b32 d_key_res[3], 0x8027fac
        .endif
    .elseiffmt amd
        SRegAlloc4A d_key_res
        .if32
            SRegAlloc1 d_key
            s_buffer_load_dword d_key, constBuf1Res, SMUL*d_key_arg
        .else
            SRegAlloc2A d_key
            s_buffer_load_dwordx2 d_key, constBuf1Res, SMUL*d_key_arg
        .endif
        s_load_dwordx4 d_key_res, uavTablePtr, SMUL*8*d_key_uav
    .endif
        s_waitcnt lgkmcnt(0)
    .if AMDCL2_OR_GALLIUM
        .ifeq ADDRBITS-32
            s_load_dwordx2 mr_ring, d_key, (Key.sett.m_ring>>2)*SMUL
        .else
            s_load_dwordx2 mr_ring, d_key_res[0:1], (Key.sett.m_ring>>2)*SMUL
        .endif
    .elseiffmt amd
        s_add_u32 d_key_res[0], d_key[0], d_key_res[0]
        .if32
            s_addc_u32 d_key_res[1], 0, d_key_res[1]
        .else
            s_addc_u32 d_key_res[1], d_key[1], d_key_res[1]
        .endif
        s_and_b32 d_key_res[1], 0xffff, d_key_res[1]
        RegFree d_key
        s_load_dwordx2 mr_ring, d_key_res[0:1], (Key.sett.m_ring>>2)*SMUL
    .endif
    
        VRegAlloc4 tempv2
        m_phase = %tempv2[0]
        canInc_l_phase = %tempv2[1]
        l_mesg = %tempv2[2]
        m_mesg = %tempv2[3]
        VRegAlloc1 r_mesg
        /*
            sett.g_mesg = d_key->sett.g_mesg;
            sett.l_mesg = (tasksNum > ALPSIZE_TO2) ? gidx / ALPSIZE_TO2 : d_key->sett.l_mesg;
            sett.m_mesg = (tasksNum > ALPSIZE) ? (gidx / ALPSIZE) % ALPSIZE : d_key->sett.m_mesg;
            sett.r_mesg = (tasksNum > 1) ? gidx % ALPSIZE : d_key->sett.r_mesg;
        */
.macro VLoadKeyValue reg, offset
    .if AMDCL2_OR_GALLIUM
        .ifeq ADDRBITS-32
            buffer_load_dword \reg, v0, bufres, d_key[0] offset:\offset
        .else
            buffer_load_dword \reg, v0, d_key_res, 0 offset:\offset
        .endif
    .elseiffmt amd
        buffer_load_dword \reg, v0, d_key_res, 0 offset:\offset
    .endif
.endm
    
        s_cmp_le_u32 tasksNum, 1
        s_cbranch_scc1 gxnumLe1
        VRegAlloc1 idby26
        VDivBy26 id, idby26
        v_mul_u32_u24 r_mesg, ALPSIZE, idby26
        VSUB_U32 r_mesg, vcc, id, r_mesg
        s_branch toSettM_mesg
gxnumLe1:
        # load r_mesg
        VLoadKeyValue r_mesg, Key.sett.r_mesg
toSettM_mesg:
        s_cmp_le_u32 tasksNum, ALPSIZE
        s_cbranch_scc1 gxnumLe26
        VDivBy26 idby26, l_mesg
        v_mul_u32_u24 m_mesg, ALPSIZE, l_mesg
        VSUB_U32 m_mesg, vcc, idby26, m_mesg
        RegFree idby26
        s_branch toSettL_mesg
gxnumLe26:
        # load m_mesg
        VLoadKeyValue m_mesg, Key.sett.m_mesg
toSettL_mesg:
        s_cmp_gt_u32 tasksNum, ALPSIZE_TO2
        s_cbranch_scc1 gxnumGt2626
        VLoadKeyValue l_mesg, Key.sett.l_mesg
gxnumGt2626:

        SRegAlloc2A mr_slot
    .if AMDCL2_OR_GALLIUM
        .ifeq ADDRBITS-32
            s_load_dwordx2 mr_slot, d_key, (Key.stru.m_slot>>2)*SMUL
            RegFree d_key
        .else
            s_load_dwordx2 mr_slot, d_key_res[0:1], (Key.stru.m_slot>>2)*SMUL
            RegFree d_key_res
        .endif
    .elseiffmt amd
        s_load_dwordx2 mr_slot, d_key_res[0:1], (Key.stru.m_slot>>2)*SMUL
        RegFree d_key_res
    .endif
        
        /*
            skip_this_key = ((gxnum > 1) &&
                (GetTurnoverLocation(&(d_key->stru), &sett, block.count, d_wiring)
                    & turnover_modes) == 0);
        */
        s_cmp_gt_u32 tasksNum, 1
    SavePool climbInitOldPool0
        s_cbranch_scc0 storeResultsToSkip
        
        /*
         * GetTurnoverLocation(&(d_key->stru), &sett, block.count, d_wiring)
         */
.macro ComputeScramblerIndexBaseV
        # load d_wiring res and ptr
    .if AMDCL2_OR_GALLIUM
    
        SRegAlloc2A d_wiring
        .ifeq ADDRBITS-32
            s_mov_b32 d_wiring[1], 0
            s_load_dword d_wiring[0], argsPtr, SMUL*d_wiring_arg
        .else
            s_load_dwordx2 d_wiring, argsPtr, SMUL*d_wiring_arg
        .endif
    
    .elseiffmt amd
        SRegAlloc2A d_wiring_res
        SRegAlloc2A d_wiring
        s_load_dwordx2 d_wiring_res, uavTablePtr, SMUL*8*d_wiring_uav
        .ifeq ADDRBITS-32
            s_buffer_load_dword d_wiring[0], constBuf1Res, SMUL*d_wiring_arg
        .else
            s_buffer_load_dwordx2 d_wiring, constBuf1Res, SMUL*d_wiring_arg
        .endif
    .endif
        s_waitcnt lgkmcnt(0)
        
    .iffmt amd
        s_and_b32 d_wiring_res[1], d_wiring_res[1], 0xffff
        s_add_u32 d_wiring[0], d_wiring_res[0], d_wiring[0]
        .ifeq ADDRBITS-32
            s_addc_u32 d_wiring[1], d_wiring_res[1], 0
        .else
            s_addc_u32 d_wiring[1], d_wiring_res[1], d_wiring[1]
        .endif
        RegFree d_wiring_res
    .endif
        # load notch_positions
        SRegAlloc1 r_notch0
        SRegAlloc1 m_notch0
        SRegAlloc1 rsoffset
        SRegAlloc1 msoffset
        s_add_u32 rsoffset, Wiring.notch_positions, mr_slot[1]
        s_add_u32 rsoffset, rsoffset, mr_slot[1]
        s_load_dword r_notch0, d_wiring, rsoffset
        s_add_u32 msoffset, Wiring.notch_positions, mr_slot[0]
        s_add_u32 msoffset, msoffset, mr_slot[0]
        s_waitcnt lgkmcnt(0)
        s_load_dword m_notch0, d_wiring, msoffset
        RegFree d_wiring
        SRegAlloc1 r_notch1
        s_and_b32 r_notch1, rsoffset, 2
        RegFree rsoffset
        s_cselect_b32 r_notch1, 16, 0
        s_lshr_b32 r_notch0, r_notch0, r_notch1
        s_bfe_i32 r_notch1, r_notch0, 0x80008
        s_sext_i32_i8 r_notch0, r_notch0
        
        /*  //period of the rotor turnovers
            int m_period = (r_notch[1] == NONE) ? ALPSIZE : HALF_ALPSIZE;
         */
        s_cmp_eq_i32 r_notch1, NONE
        SRegAlloc1 m_period
        s_cselect_b32 m_period, ALPSIZE, HALF_ALPSIZE
        /*  //current wheel position relative to the last notch
            int r_after_notch = sett->r_mesg - r_notch[0];
            if (r_after_notch < 0) r_after_notch += ALPSIZE;
            if (r_notch[1] != NONE && r_after_notch >= (r_notch[1] - r_notch[0]))
                r_after_notch -= r_notch[1] - r_notch[0];
         */
        VRegAlloc1 r_after_notch
        VRegAlloc1 r_after_notch1
        s_waitcnt vmcnt(2)
        VSUB_U32 r_after_notch, vcc, r_mesg, r_notch0
        v_cndmask_b32 r_after_notch1, 0, ALPSIZE, vcc
        VADD_U32 r_after_notch, vcc, r_after_notch, r_after_notch1
        RegFree r_after_notch1
        RegFree r_notch0    # last usage
        SRegAlloc1 r_notch_diff
        s_sub_u32 r_notch_diff, r_notch1, r_notch0
        s_cmp_lg_i32 r_notch1, NONE
        s_cbranch_scc0 CScrmbJump0_\@
        v_cmpx_ge_i32 vcc, r_after_notch, r_notch_diff
        VSUB_U32 r_after_notch, vcc, r_after_notch, r_notch_diff
CScrmbJump0_\@:
        RegFree r_notch_diff
        RegFree r_notch1
        s_mov_b64 exec, tmpexec
        
        /*  //middle wheel turnover phase
            int m_phase = r_after_notch - 1;
            if (m_phase < 0) m_phase += m_period;
            */
        VSUBREV_U32 m_phase, vcc, 1, r_after_notch
        v_cmpx_gt_i32 vcc, 0, m_phase
        VADD_U32 m_phase, vcc, m_period, m_phase
        s_mov_b64 exec, tmpexec
        
        s_waitcnt lgkmcnt(0)
        ##################################
        # process m_notch0 and m_notch1
        SRegAlloc1 m_notch1
        s_and_b32 m_notch1, msoffset, 2
        RegFree msoffset
        s_cselect_b32 m_notch1, 16, 0
        s_lshr_b32 m_notch0, m_notch0, m_notch1
        s_bfe_i32 m_notch1, m_notch0, 0x80008
        s_sext_i32_i8 m_notch0, m_notch0
        
        /* int l_period = (m_notch[1] == NONE) ? ALPSIZE : HALF_ALPSIZE;
           l_period = (l_period-1) * m_period; */
        SRegAlloc1 l_period_const1
        SRegAlloc1 l_period_const2
        SRegAlloc1 l_period
        # consts for 1.0/312
        s_mov_b32 l_period_const1, 6882960
        s_mov_b32 l_period_const2, 3441400
        s_cmp_eq_i32 m_notch1, NONE
        # if m_notch1==NONE the consts for 1.0/650
        s_cselect_b32 l_period_const1, 3303821, l_period_const1
        s_cselect_b32 l_period_const2, 1650000, l_period_const2
        s_cselect_b32 l_period, ALPSIZE, HALF_ALPSIZE
        s_mul_i32 l_period, l_period, m_period
        s_sub_i32 l_period, l_period, m_period
        
        /* int m_after_notch = sett->m_mesg - m_notch[0];
            if (m_after_notch < 0) m_after_notch += ALPSIZE;
            if (m_notch[1] != NONE && m_after_notch >= (m_notch[1] - m_notch[0]))
                m_after_notch -= m_notch[1] - m_notch[0];
        */
        VRegAlloc1 m_after_notch
        VRegAlloc1 m_after_notch1
        s_waitcnt vmcnt(1)
        VSUB_U32 m_after_notch, vcc, m_mesg, m_notch0
        v_cndmask_b32 m_after_notch1, 0, ALPSIZE, vcc
        VADD_U32 m_after_notch, vcc, m_after_notch, m_after_notch1
        RegFree m_after_notch1
        RegFree m_notch0    # last usage
        SRegAlloc1 m_notch_diff
        s_sub_u32 m_notch_diff, m_notch1, m_notch0
        s_cmp_lg_i32 m_notch1, NONE
        s_cbranch_scc0 CScrmbJump1_\@
        v_cmpx_ge_i32 vcc, m_after_notch, m_notch_diff
        VSUB_U32 m_after_notch, vcc, m_after_notch, m_notch_diff
CScrmbJump1_\@:
        RegFree m_notch_diff
        RegFree m_notch1
        s_mov_b64 exec, tmpexec
    
        /* //left wheel turnover phase
            int l_phase = m_phase - 1 + (m_after_notch - 1) * m_period;
            if (l_phase < 0) l_phase += l_period;
        */
        VRegAlloc1 l_phase
        v_mul_u32_u24 l_phase, m_after_notch, m_period
        VSUB_U32 l_phase, vcc, l_phase, m_period
        VADD_U32 l_phase, vcc, l_phase, m_phase
        VSUBREV_U32 l_phase, vcc, 1, l_phase
        v_cmpx_gt_i32 vcc, 0, l_phase
        VADD_U32 l_phase, vcc, l_phase, l_period
        s_mov_b64 exec, tmpexec
        
        /*  //hacks
            if (m_after_notch == 0) l_phase += m_period;
            if (m_after_notch == 1 && r_after_notch == 1)
                l_phase -= l_period; //effectively sets l_phase to -1
        */
        v_cmpx_eq_i32 vcc, 0, m_after_notch
        VADD_U32 l_phase, vcc, m_period, l_phase
        s_mov_b64 exec, tmpexec
        v_cmpx_eq_i32 vcc, 1, m_after_notch
        v_cmpx_eq_i32 vcc, 1, r_after_notch
        VSUBREV_U32 l_phase, vcc, l_period, l_phase
        s_mov_b64 exec, tmpexec
        RegFree l_period
        
        /* if (m_after_notch == 0 && r_after_notch == 0)
            {
                m_phase -= m_period;
                l_phase -= m_period;
                if (char_pos == 0) l_phase++;
            } */
        v_mov_b32 canInc_l_phase, 0
        v_cmpx_eq_u32 vcc, 0, m_after_notch
        v_cmpx_eq_u32 vcc, 0, r_after_notch
        s_cbranch_execz CScrmbJump2_\@
        v_mov_b32 canInc_l_phase, 1
        VSUBREV_U32 m_phase, vcc, m_period, m_phase
        VSUBREV_U32 l_phase, vcc, m_period, l_phase
CScrmbJump2_\@:
        s_mov_b64 exec, tmpexec
.endm

.macro ComputeScramblerIndexNextV2 char_pos, scramblerLast, literal, tmpexec
        ########################
        # next part
        ########################
        
        l_phase_alloc = 1
    .ifeqs "\char_pos", "0"
        VRegAlloc1 l_phase_n
        VADD_U32 l_phase_n, vcc, l_phase, canInc_l_phase
    .elseifeq \literal  # if not literal
        v_cmpx_eq_u32 vcc, 0, \char_pos
        VADD_U32 l_phase_n, vcc, l_phase, canInc_l_phase
        s_mov_b64 exec, \tmpexec
    .else
        l_phase_alloc = 0
        l_phase_n = %l_phase
    .endif
    
        /* int m_steps = (m_phase + char_pos + 1) / m_period; */
        VRegAlloc1 m_steps
    .ifnes "\char_pos", "0"
        .if \literal
            VADD_U32 m_steps, vcc, 1+\char_pos, m_phase
        .else
            VADD_U32 m_steps, vcc, \char_pos, m_phase
            VADD_U32 m_steps, vcc, 1, m_steps
        .endif
    .else
        VADD_U32 m_steps, vcc, 1, m_phase
    .endif
        v_cmpx_eq_i32 vcc, HALF_ALPSIZE, m_period
        v_lshlrev_b32 m_steps, 1, m_steps
        s_mov_b64 exec, \tmpexec
        VSDivBy26 m_steps, m_steps
        /* int l_steps = (l_phase + char_pos + 1) / l_period; */
        VRegAlloc1 l_steps
    .ifnes "\char_pos", "0"
        .if \literal
            VADD_U32 l_steps, vcc, 1+\char_pos, l_phase_n
        .else
            VADD_U32 l_steps, vcc, \char_pos, l_phase_n
            VADD_U32 l_steps, vcc, 1, l_steps
        .endif
    .else
        VADD_U32 l_steps, vcc, 1, l_phase_n
    .endif
    .if l_phase_alloc
        RegFree l_phase_n
    .endif
    
        v_cmpx_eq_i32 vcc, HALF_ALPSIZE, m_period
        v_lshlrev_b32 l_steps, 1, l_steps
        s_mov_b64 exec, \tmpexec
        VSDivByX l_steps, l_steps, l_period_const1, l_period_const2
        
        VADD_U32 m_steps, vcc, m_steps, l_steps
        VADD_U32 l_steps, vcc, l_mesg, l_steps
    .ifnb \scramblerLast
        # we have only scramblerLast part
        VMod26Fn l_steps, \scramblerLast
    .else
        .error "Not supported condition for ComputeScramblerIndexNext"
    .endif
        RegFree l_steps
        RegFree m_steps
.endm

        VRegAlloc1 turnoverVal
        v_mov_b32 turnoverVal, toAfterMessage
        
    .if TURNOVER_MODES & toAfterMessage
        ComputeScramblerIndexBaseV
    .endif
    
        /* //rotors with two notches
            if (stru->r_slot > rotV && sett->r_ring >= HALF_ALPSIZE) 
                return toAfterMessage;
            if (stru->m_slot > rotV && sett->m_ring >= HALF_ALPSIZE) 
                return toAfterMessage;
        */
        s_waitcnt lgkmcnt(0)    # mr_slot
        SRegAlloc2A tmpcond
        v_cmp_gt_i32 vcc, mr_slot[1], rotV
        v_cmp_ge_i32 tmpcond, mr_ring[1], HALF_ALPSIZE
        s_and_b64 tmpcond, vcc, tmpcond
    .ifne TURNOVER_MODES & toAfterMessage
        s_cbranch_scc1 storeResults
    .else
        s_cbranch_scc1 storeResultsToSkip
    .endif
    
        v_cmp_gt_i32 vcc, mr_slot[0], rotV
        v_cmp_ge_i32 tmpcond, mr_ring[0], HALF_ALPSIZE
        s_and_b64 tmpcond, vcc, tmpcond
    .ifne TURNOVER_MODES & toAfterMessage
        s_cbranch_scc1 storeResults
    .else
        s_cbranch_scc1 storeResultsToSkip
    .endif
        RegFree tmpcond
        
        # int8_t l_core_before = mod26(sett->l_mesg - sett->l_ring);
        VRegAlloc1 l_core_first
    .ifeq TURNOVER_MODES & toAfterMessage
        ComputeScramblerIndexBaseV
    .endif
        s_waitcnt vmcnt(0)
        VRegAlloc1 l_core_before
        VMod26Fn l_mesg, l_core_before
    
        ComputeScramblerIndexNextV2 0, l_core_first, 1, tmpexec
        
        v_mov_b32 turnoverVal, toBeforeMessage
        v_cmpx_eq_u32 vcc, l_core_first, l_core_before
        s_cbranch_execz storeResults
    
        RegFree l_core_before
        
        VRegAlloc1 l_core_last
        /* int8_t l_core_last = 
                ComputeScramblerIndex(ciphertext_length-1, stru, sett, wiring) 
                / ALPSIZE_TO2;
        if (l_core_last != l_core_first) return toDuringMessage; */
        SRegAlloc2A tmpexec2
        s_mov_b64 tmpexec2, exec
        ComputeScramblerIndexNextV2 (TASK_SIZE-1), l_core_last, 1, tmpexec2
        RegFree tmpexec2
    /*.if DEBUG_CLIMBINIT
        s_waitcnt lgkmcnt(0)
        #v_mov_b32 l_core_last, 55465
        DUMP_VREG l_core_last
    .endif*/
        v_mov_b32 turnoverVal, toDuringMessage
        v_cmpx_eq_u32 vcc, l_core_first, l_core_last
        s_cbranch_execz storeResults
    
        v_mov_b32 turnoverVal, toAfterMessage
        
storeResults:
        s_mov_b64 exec, tmpexec
        SRegAlloc2A skipTestMask
        v_and_b32 turnoverVal, turnoverVal, TURNOVER_MODES
        v_cmp_eq_u32 skipTestMask, 0, turnoverVal
        
.macro InitStoreResults
    .if AMDCL2_OR_GALLIUM
        .ifeq ADDRBITS-32
            SRegAlloc1 tempClimbData
            s_load_dword tempClimbData, argsPtr, tempClimbData_arg*SMUL
        .else
            SRegAlloc4A tempClimbData_res
            s_load_dwordx2 tempClimbData_res[0:1], argsPtr, tempClimbData_arg*SMUL
            s_movk_i32 tempClimbData_res[2], 0xffff
            s_mov_b32 tempClimbData_res[3], 0x8027fac
        .endif
    .elseiffmt amd
        SRegAlloc4A tempClimbData_res
        .ifeq ADDRBITS-32
            SRegAlloc1 tempClimbData
            s_buffer_load_dword tempClimbData, constBuf1Res, SMUL*tempClimbData_arg
        .else
            SRegAlloc2A tempClimbData
            s_buffer_load_dwordx2 tempClimbData, constBuf1Res, SMUL*tempClimbData_arg
        .endif
        s_load_dwordx4 tempClimbData_res, uavTablePtr, SMUL*8*tempClimbData_uav
    .endif
        s_waitcnt lgkmcnt(0)
    .iffmt amd
        .ifeq ADDRBITS-64
            s_add_u32 tempClimbData_res[0], tempClimbData_res[0], tempClimbData[0]
            s_addc_u32 tempClimbData_res[1], tempClimbData_res[1], tempClimbData[1]
            RegFree tempClimbData
        .endif
    .endif
.endm
        InitStoreResults
    
        VRegAlloc1 id48
        v_mul_u32_u24 id48, 48, id
        
    .macro VStoreTempClimb reg, offset
        .if AMDCL2_OR_GALLIUM
            .ifeq ADDRBITS-32
                buffer_store_dword \reg, id48, bufres, tempClimbData offen offset:\offset
            .else
                buffer_store_dword \reg, id48, tempClimbData_res, 0 offen offset:\offset
            .endif
        .elseiffmt amd
            .ifeq ADDRBITS-32
                buffer_store_dword \reg, id48, tempClimbData_res, tempClimbData offen \
                            offset:\offset
            .else
                buffer_store_dword \reg, id48, tempClimbData_res, 0 offen offset:\offset
            .endif
        .endif
    .endm
    .macro VStoreTempClimbX4 reg, offset
        .if AMDCL2_OR_GALLIUM
            .ifeq ADDRBITS-32
                buffer_store_dwordx4 \reg, id48, bufres, tempClimbData offen offset:\offset
            .else
                buffer_store_dwordx4 \reg, id48, tempClimbData_res, 0 offen offset:\offset
            .endif
        .elseiffmt amd
            .ifeq ADDRBITS-32
                buffer_store_dwordx4 \reg, id48, tempClimbData_res, tempClimbData offen \
                            offset:\offset
            .else
                buffer_store_dwordx4 \reg, id48, tempClimbData_res, 0 offen offset:\offset
            .endif
        .endif
    .endm
    
        VRegAlloc1 tempv0
        VRegAlloc4 tempv
        v_cndmask_b32 tempv0, 0, 1, skipTestMask
        VStoreTempClimb tempv0, 0
        s_andn2_b64 exec, exec, skipTestMask
        s_cbranch_execz skipPassedTasks
        # passed tasks lanes
        v_mov_b32 tempv[0], l_period_const1
        v_mov_b32 tempv[1], l_period_const2
        v_mov_b32 tempv[2], l_phase
        v_mov_b32 tempv[3], m_period
        VStoreTempClimbX4 tempv, 4
        VStoreTempClimbX4 tempv2, 20
        VStoreTempClimb r_mesg, 36
skipPassedTasks:
endOfClimbInit:
        s_endpgm

storeResultsToSkip:
    RestorePool climbInitOldPool0
        InitStoreResults
    
        VRegAlloc1 id48
        v_mul_u32_u24 id48, 48, id
    
        VRegAlloc1 tempv0
        v_mov_b32 tempv0, 0
        VStoreTempClimb tempv0, 0
        s_endpgm

.ends
    ResetPool
.iffmt gallium
.p2align 8
.endif

####
# kernel
####

.scope

.kernel ClimbKernel
    .config
    local_scrambler_size = ((TASK_SIZE + (SCRAMBLER_STRIDE-1)) & \
                    ~(SCRAMBLER_STRIDE-1)) * 28
        
    LocalPlugs = 0
    LocalUnigrams = 32
    LocalTemps = LocalUnigrams+128
    LocalScoreBuf = LocalUnigrams+128
    LocalTmpSums = LocalScoreBuf+128
    LocalScrambler = LocalTmpSums+32
    LocalOldScoreInd = LocalTmpSums+28
    LocalPlainText = LocalScrambler + local_scrambler_size
    
        .dims x
        .localsize 32 + 128 + 128 + 32 + TASK_SIZE + local_scrambler_size
    .iffmt amdcl2
        .dx10clamp
        .ieeemode
        .useargs
        .usesetup
        .setupargs
        .arg d_wiring, "Wiring*", structure*, 1024, constant, const, rdonly
        .arg d_key, "Key*", structure*, 64, constant, const, rdonly
        .arg scramblerData, "int8_t*", char*, global, const, rdonly
        .arg trigramsData, "int*", int*, global, const, rdonly
        .arg d_unigrams, "int*", int*, constant, const, rdonly
        .arg d_bigrams, "int*", int*, constant, const, rdonly
        .arg d_plugs, "int8_t*", char*, constant, const, rdonly
        .arg d_order, "int8_t*", char*, constant, const, rdonly
        .arg d_fixed, "int", int
        .arg d_ciphertext, "int8_t*", char*, constant, const, rdonly
        .arg taskResults, "Result*", structure*, 64, global, 
        .arg tempClimbData, "ClimbTempEntry*", structure*, 64, global, const
    .if DEBUG&1
        .arg sdebugOut, "uint*", char*, global,
    .endif
    .if DEBUG&2
        .arg vdebugOut, "uint*", char*, global,
    .endif
        
    SRegAlloc2At setupPtr, 4
    SRegAlloc2At argsPtr, 6
    .ifge ARCH-GCN14
        SRegAlloc1At gid, 10
    .else
        SRegAlloc1At gid, 8
    .endif
    .ifeq ADDRBITS-32
        d_wiring_arg = 6
        d_key_arg = 7
        scramblerData_arg = 8
        trigramsData_arg = 9
        d_unigrams_arg = 10
        d_bigrams_arg = 11
        d_plugs_arg = 12
        d_order_arg = 13
        d_fixed_arg = 14
        d_ciphertext_arg = 15
        taskResults_arg = 16
        tempClimbData_arg = 17
        nextDebug_arg = tempClimbData_arg+1
        .if DEBUG&1
            sdebugOut_arg = nextDebug_arg
            nextDebug_arg = nextDebug_arg+1
        .endif
        .if DEBUG&2
            vdebugOut_arg = nextDebug_arg
        .endif
    .else
        d_wiring_arg = 12
        d_key_arg = 14
        scramblerData_arg = 16
        trigramsData_arg = 18
        d_unigrams_arg = 20
        d_bigrams_arg = 22
        d_plugs_arg = 24
        d_order_arg = 26
        d_fixed_arg = 28
        d_ciphertext_arg = 30
        taskResults_arg = 32
        tempClimbData_arg = 34
        nextDebug_arg = tempClimbData_arg+2
        .if DEBUG&1
            sdebugOut_arg = nextDebug_arg
            nextDebug_arg = nextDebug_arg+2
        .endif
        .if DEBUG&2
            vdebugOut_arg = nextDebug_arg
        .endif
    .endif
        
    .ifge ARCH-GCN14
        sgprUserNum = 10
    .else
        sgprUserNum = 8
    .endif
        freeSgprUser = 4    # scratch buffer not used
    .elseiffmt amd
        .uavid 11
        .uavprivate 0
        .printfid 9
        .privateid 8
        .cbid 10
        .userdata ptr_uav_table, 0, 2, 2
        .userdata imm_const_buffer, 0, 4, 4
        .userdata imm_const_buffer, 1, 8, 4
        .arg d_wiring, "Wiring*", structure*, 1024, constant, const
        .arg d_key, "Key*", structure*, 64, constant, const
        .arg scramblerData, "int8_t*", void*, global, const
        .arg trigramsData, "int*", int*, global, const
        .arg d_unigrams, "int*", int*, constant, const
        .arg d_bigrams, "int*", int*, constant, const
        .arg d_plugs, "int8_t*", void*, constant, const
        .arg d_order, "int8_t*", void*, constant, const
        .arg d_fixed, "int", int
        .arg d_ciphertext, "int8_t*", void*, constant, const
        .arg taskResults, "Result*", structure*, 64, global
        .arg tempClimbData, "ClimbTempEntry*", structure*, 64, global, const
    .if DEBUG&1
        .arg sdebugOut, "uint*", char*, global,
    .endif
    .if DEBUG&2
        .arg vdebugOut, "uint*", char*, global,
    .endif
        
        SRegAlloc2At uavTablePtr, 2
        SRegAlloc4At constBuf0Res, 4
        SRegAlloc4At constBuf1Res, 8
        SRegAlloc1At gid, 12
        
        d_wiring_arg = 0
        d_key_arg = 4
        scramblerData_arg = 8
        trigramsData_arg = 12
        d_unigrams_arg = 16
        d_bigrams_arg = 20
        d_plugs_arg = 24
        d_order_arg = 28
        d_fixed_arg = 32
        d_ciphertext_arg = 36
        taskResults_arg = 40
        tempClimbData_arg = 44
        nextDebug_arg = tempClimbData_arg+4
        .if DEBUG&1
            sdebugOut_arg = nextDebug_arg
            nextDebug_arg = nextDebug_arg+4
        .endif
        .if DEBUG&2
            vdebugOut_arg = nextDebug_arg
        .endif
        
        uavStart = 12
        d_wiring_uav = uavStart+0
        d_key_uav = uavStart+1
        scramblerData_uav = uavStart+2
        trigramsData_uav = uavStart+3
        d_unigrams_uav = uavStart+4
        d_bigrams_uav = uavStart+5
        d_plugs_uav = uavStart+6
        d_order_uav = uavStart+7
        d_ciphertext_uav = uavStart+8
        taskResults_uav = uavStart+9
        tempClimbData_uav = uavStart+10
        nextDebug_uav = tempClimbData_uav+1
        .if DEBUG&1
            sdebugOut_uav = nextDebug_uav
            nextDebug_uav = nextDebug_uav+1
        .endif
        .if DEBUG&2
            vdebugOut_uav = nextDebug_uav
        .endif
        
        sgprUserNum = 12
        freeSgprUser = 2
    
    .elseiffmt gallium
        .iflt LLVMVER-40000
            .dims xyz   # gallium set always three dimensions by Gallium
            .tgsize     # TG_SIZE_EN is always enabled by Gallium
        .endif
    .args
        .arg global, 8      # d_wiring
        .arg global, 8      # d_key
        .arg global, 8      # scramblerData
        .arg global, 8      # trigramsData
        .arg global, 8      # d_unigrams
        .arg global, 8      # d_bigrams
        .arg global, 8      # d_plugs
        .arg global, 8      # d_order
        .arg scalar, 4      # d_fixed
        .arg global, 8      # d_ciphertext
        .arg global, 8      # taskResults
        .arg global, 8      # tempClimbData
    .if DEBUG_CLIMBINIT
        .arg scalar, 8      # vdebugOut
    .endif
        .arg griddim, 4
        .arg gridoffset, 4
        
        .ifge LLVMVER-40000
        
        .config
            .dims x
            .dx10clamp
            .ieeemode
            .default_hsa_features
            
            d_wiring_arg = 0
            d_key_arg = 2
            scramblerData_arg = 4
            trigramsData_arg = 6
            d_unigrams_arg = 8
            d_bigrams_arg = 10
            d_plugs_arg = 12
            d_order_arg = 14
            d_fixed_arg = 16
            d_ciphertext_arg = 18
            taskResults_arg = 20
            tempClimbData_arg = 22
        .if DEBUG_CLIMBINIT
            vdebugOut_arg = 24     # vdebugOut
        .endif
        
            SRegAlloc2At argsPtr, 6
            SRegAlloc1At gid, 8
            
        .else # old LLVM
            
            d_wiring_arg = 9
            d_key_arg = 11
            scramblerData_arg = 13
            trigramsData_arg = 15
            d_unigrams_arg = 17
            d_bigrams_arg = 19
            d_plugs_arg = 21
            d_order_arg = 23
            d_fixed_arg = 25
            d_ciphertext_arg = 27
            taskResults_arg = 29
            tempClimbData_arg = 31
        .if DEBUG_CLIMBINIT
            vdebugOut_arg = 33     # vdebugOut
        .endif
            
            sgprUserNum = 8
            SRegAlloc2At argsPtr, 0
            SRegAlloc1At gid, 4
        .endif
    .else
        .error "Unsupported binary format"
    .endif
    
    VRegAlloc1At lid, 0
    /*
     * MAIN CODE - main code of ClimbKernel
     */
    .text
.iffmt gallium
::ClimbKernel:
.ifge LLVMVER-40000
    .skip 256
.endif
.endif
        s_mov_b32 m0, 0x10000
        # load tempdata addreses
    .if AMDCL2_OR_GALLIUM
        .ifeq ADDRBITS-32
            SRegAlloc2A tempClimbData
            s_load_dword tempClimbData[0], argsPtr, SMUL*tempClimbData_arg
            s_mov_b32 tempClimbData[1], 0
        .else
            SRegAlloc2A tempClimbData
            s_load_dwordx2 tempClimbData, argsPtr, SMUL*tempClimbData_arg
        .endif
    .elseiffmt amd
        SRegAlloc2A tempClimbData_res
        .ifeq ADDRBITS-32
            SRegAlloc2A tempClimbData
            s_buffer_load_dword tempClimbData[0], constBuf1Res, SMUL*tempClimbData_arg
        .else
            SRegAlloc2A tempClimbData
            s_buffer_load_dwordx2 tempClimbData, constBuf1Res, SMUL*tempClimbData_arg
        .endif
        s_load_dwordx2 tempClimbData_res, uavTablePtr, SMUL*8*tempClimbData_uav
    .endif
        s_waitcnt lgkmcnt(0)
    .iffmt amd
    # prepare tempClimbData pointer
        s_and_b32 tempClimbData_res[1], tempClimbData_res[1], 0xffff
        s_add_u32 tempClimbData[0], tempClimbData[0], tempClimbData_res[0]
        .ifeq ADDRBITS-32
            s_addc_u32 tempClimbData[1], 0, tempClimbData_res[1]
        .else
            s_addc_u32 tempClimbData[1], tempClimbData[1], tempClimbData_res[1]
        .endif
        RegFree tempClimbData_res
    .endif
        
        SRegAlloc1 gid48
        s_mul_i32 gid48, 48, gid
        
        SRegAlloc1 skip_this_key
        s_load_dword skip_this_key, tempClimbData, gid48
        s_waitcnt lgkmcnt(0)
        
        s_cmp_eq_i32 skip_this_key, 0
        
        RegFree skip_this_key
        s_cbranch_scc1 ClimbNoEnd
        
        ############################################
        # store result 
        SavePool OldPool
        RegFree tempClimbData
        RegFree gid48
        # end of processing: this is not task
    .ifgt TASK_SIZE-64
        v_cmpx_eq_u32 vcc, lid, 0
        s_cbranch_execz endOfClimb0
    .endif
    
    .if AMDCL2_OR_GALLIUM
        .ifeq ADDRBITS-32
            SRegAlloc4A bufres
            SRegAlloc1 taskResults
            s_load_dword taskResults, argsPtr, SMUL*taskResults_arg
            s_mov_b64 bufres[0:1], 0
            s_movk_i32 bufres[2], 0xffff
            s_mov_b32 bufres[3], 0x8027fac
        .else # 64-bit
            SRegAlloc4A taskResults_res
            s_load_dwordx2 taskResults_res[0:1], argsPtr, SMUL*taskResults_arg
            s_movk_i32 taskResults_res[2], 0xffff
            s_mov_b32 taskResults_res[3], 0x8027fac
        .endif
    .elseiffmt amd
        SRegAlloc4A taskResults_res
        s_load_dwordx4 taskResults_res, uavTablePtr, SMUL*8*taskResults_uav
        .ifeq ADDRBITS-32
            SRegAlloc1 taskResults
            s_buffer_load_dword taskResults, constBuf1Res, SMUL*taskResults_arg
        .else
            SRegAlloc2A taskResults
            s_buffer_load_dwordx2 taskResults, constBuf1Res, SMUL*taskResults_arg
        .endif
    .endif
        s_waitcnt lgkmcnt(0)
        s_mov_b64 exec, 1 # only lane
        VRegAlloc1At gidv, 1
        v_mov_b32 gidv, gid
        v_mov_b32 lid, -1 # score=-1, index = 
    
    .if AMDCL2_OR_GALLIUM
        s_mul_i32 gid, gid, ResultSize
        .ifeq ADDRBITS-32
            s_add_u32 taskResults[0], taskResults[0], gid
            buffer_store_dwordx2 v[0:1], v0, bufres, taskResults offset:28
            RegFree taskResults
        .else
            buffer_store_dwordx2 v[0:1], v0, taskResults_res, gid offset:28
            RegFree taskResults_res
        .endif
    .elseiffmt amd
        s_mul_i32 gid, gid, ResultSize
        s_add_u32 taskResults[0], taskResults[0], gid
        .ifeq ADDRBITS-32
            buffer_store_dwordx2 v[0:1], v0, taskResults_res, taskResults offset:28
        .else
            s_addc_u32 taskResults[1], taskResults[1], 0
            s_add_u32 taskResults_res[0], taskResults_res[0], taskResults[0]
            s_addc_u32 taskResults_res[1], taskResults_res[1], taskResults[1]
            buffer_store_dwordx2 v[0:1], v0, taskResults_res, 28
        .endif
        RegFree taskResults
        RegFree taskResults_res
    .endif
    
    .ifgt TASK_SIZE-64
endOfClimb0:
    .endif
        s_endpgm
ClimbNoEnd:
    RestorePool OldPool
        
        ######################################
        # to process
        ###########
        
        # load d_plugs,d_unigrams addresses
    .if AMDCL2_OR_GALLIUM
        
        .ifeq ADDRBITS-32
            SRegAlloc1 d_plugs
            SRegAlloc1 d_unigrams
        .else
        .ifeq ARCH-GCN10
            SRegAlloc4A d_plugs
            SRegAlloc4A d_unigrams
        .else
            SRegAlloc2A d_plugs
            SRegAlloc2A d_unigrams
        .endif
        .endif
        .ifeq ADDRBITS-32
            SRegAlloc4A bufres
            s_load_dword d_plugs, argsPtr, SMUL*d_plugs_arg
            s_load_dword d_unigrams, argsPtr, SMUL*d_unigrams_arg
            s_mov_b64 bufres[0:1], 0
            s_movk_i32 bufres[2], 0xffff
            s_mov_b32 bufres[3], 0x8027fac
        .else
        .ifeq ARCH-GCN10
            s_movk_i32 d_plugs[2], 0xffff
            s_mov_b32 d_plugs[3], 0x8027fac
            s_mov_b64 d_unigrams[2:3], d_plugs[2:3]
        .endif
            s_load_dwordx2 d_plugs[0:1], argsPtr, SMUL*d_plugs_arg
            s_load_dwordx2 d_unigrams[0:1], argsPtr, SMUL*d_unigrams_arg
        .endif
        s_waitcnt lgkmcnt(0)
        
    .elseiffmt amd
    
        .ifeq ADDRBITS-32
            SRegAlloc1 d_plugs
            SRegAlloc1 d_unigrams
        .else
            SRegAlloc2A d_plugs
            SRegAlloc2A d_unigrams
        .endif # bit
        SRegAlloc4A d_plugs_res
        SRegAlloc4A d_unigrams_res
        s_load_dwordx4 d_plugs_res, uavTablePtr, SMUL*8*d_plugs_uav
        s_load_dwordx4 d_unigrams_res, uavTablePtr, SMUL*8*d_unigrams_uav
        .ifeq ADDRBITS-32
            s_buffer_load_dword d_plugs, constBuf1Res, SMUL*d_plugs_arg
            s_buffer_load_dword d_unigrams, constBuf1Res, SMUL*d_unigrams_arg
        .else
            s_buffer_load_dwordx2 d_plugs, constBuf1Res, SMUL*d_plugs_arg
            s_buffer_load_dwordx2 d_unigrams, constBuf1Res, SMUL*d_unigrams_arg
        .endif # bit
        s_waitcnt lgkmcnt(0)
    .endif
        
        VRegAlloc1 lid4
        v_lshlrev_b32 lid4, 2, lid
        VRegAlloc2 plugunigram
        
        /*  if (lid < ALPSIZE)
            {
                block.plugs[lid] = d_plugs[lid];
                block.unigrams[lid] = d_unigrams[lid];
            } */
        v_cmpx_gt_u32 vcc, ALPSIZE, lid
    .ifgt TASK_SIZE-64
        s_cbranch_execz skipFeedToLds
    .endif
        
    .if AMDCL2_OR_GALLIUM
    
        .ifeq ADDRBITS-32
            buffer_load_sbyte plugunigram[0], lid, bufres, d_plugs offen
            buffer_load_dword plugunigram[1], lid4, bufres, d_unigrams offen
        .else
        .ifeq ARCH-GCN10
            buffer_load_sbyte plugunigram[0], lid, d_plugs, 0 offen
            buffer_load_dword plugunigram[1], lid4, d_unigrams, 0 offen
        .else
            VADD_U32 plugunigram[0], vcc, d_plugs[0], lid
            v_mov_b32 plugunigram[1], d_plugs[1]
            VADDC_U32 plugunigram[1], vcc, 0, plugunigram[1], vcc
            flat_load_sbyte plugunigram[0], plugunigram
            
            VRegAlloc2 tmpaddr
            VADD_U32 tmpaddr[0], vcc, d_unigrams[0], lid4
            v_mov_b32 tmpaddr[1], d_unigrams[1]
            VADDC_U32 tmpaddr[1], vcc, 0, tmpaddr[1], vcc
            flat_load_dword plugunigram[1], tmpaddr
            RegFree tmpaddr
        .endif
        .endif
        
        RegFree d_plugs
        RegFree d_unigrams
    .elseiffmt amd
        .ifeq ADDRBITS-32
            buffer_load_sbyte plugunigram[0], lid, d_plugs_res, d_plugs offen
            buffer_load_dword plugunigram[1], lid4, d_unigrams_res, d_unigrams offen
        .else
            s_add_u32 d_plugs_res[0], d_plugs_res[0], d_plugs[0]
            s_addc_u32 d_plugs_res[1], d_plugs_res[1], d_plugs[1]
            buffer_load_sbyte plugunigram[0], lid, d_plugs_res, 0 offen
            s_add_u32 d_unigrams_res[0], d_unigrams_res[0], d_unigrams[0]
            s_addc_u32 d_unigrams_res[1], d_unigrams_res[1], d_unigrams[1]
            buffer_load_dword plugunigram[1], lid4, d_unigrams_res, 0 offen
        .endif
        RegFree d_plugs
        RegFree d_unigrams
        RegFree d_plugs_res
        RegFree d_unigrams_res
    .endif
    
        s_waitcnt vmcnt(1)
        ds_write_b8 lid, plugunigram[0] offset:LocalPlugs
        s_waitcnt vmcnt(0)
        ds_write_b32 lid4, plugunigram[1] offset:LocalUnigrams
        
    .ifeq USE_LOCAL_IN_TRYSWAP
        # keep plugunigram[0] for later usage (in tryswap and calculations)
        VRegAlloc1At d_plugsVal, plugunigram__index
    .endif
    
    .ifgt TASK_SIZE-64
skipFeedToLds:
    .endif
        s_mov_b64 exec, -1
    
    # load d_key struct
    .if AMDCL2_OR_GALLIUM
        .ifeq ADDRBITS-32
            SRegAlloc2A d_key
            s_load_dword d_key[0], argsPtr, SMUL*d_key_arg
            s_mov_b32 d_key[1], 0
        .else
            SRegAlloc2A d_key
            s_load_dwordx2 d_key, argsPtr, SMUL*d_key_arg
        .endif
    .elseiffmt amd
        SRegAlloc2A d_key_res
        .ifeq ADDRBITS-32
            SRegAlloc2A d_key
            s_buffer_load_dword d_key[0], constBuf1Res, SMUL*d_key_arg
        .else
            SRegAlloc2A d_key
            s_buffer_load_dwordx2 d_key, constBuf1Res, SMUL*d_key_arg
        .endif
        s_load_dwordx2 d_key_res, uavTablePtr, SMUL*8*d_key_uav
    .endif
        s_waitcnt lgkmcnt(0)
    .iffmt amd
    # prepare d_key pointer
        s_and_b32 d_key_res[1], d_key_res[1], 0xffff
        s_add_u32 d_key[0], d_key[0], d_key_res[0]
        .ifeq ADDRBITS-32
            s_addc_u32 d_key[1], 0, d_key_res[1]
        .else
            s_addc_u32 d_key[1], d_key[1], d_key_res[1]
        .endif
        RegFree d_key_res
    .endif
            
       /*   if (lid == 0)
            {
            block.count = taskCount;
            
            //ring and rotor settings to be tried
            sett.g_ring = 0;
            sett.l_ring = 0;
            // for this code no code, because are constant and not modifiable later
            
            // we assume gynum==1
            //depending on the grid size, ring positions 
            //either from grid index or fixed (from d_key)
            sett.m_ring = (gynum > ALPSIZE) ? gidy / ALPSIZE : d_key->sett.m_ring;
            sett.r_ring = (gynum > 1) ? gidy % ALPSIZE : d_key->sett.r_ring;
            
            sett.g_mesg = d_key->sett.g_mesg;
        */
    # load d_key->sett.m_ring and r_ring
        SRegAlloc2A mr_ring
        sett.m_ring = %mr_ring[0]
        sett.r_ring = %mr_ring[1]
        /* sett.l_mesg = (gxnum > ALPSIZE_TO2) ? gidx / ALPSIZE_TO2 : d_key->sett.l_mesg;
         * sett.m_mesg = (gxnum > ALPSIZE) ? (gidx / ALPSIZE) % ALPSIZE : d_key->sett.m_mesg;
         * sett.r_mesg = (gxnum > 1) ? gidx % ALPSIZE : d_key->sett.r_mesg;
         */
    
        s_load_dwordx2 mr_ring, d_key, (Key.sett.m_ring>>2)*SMUL
        
        /* {
            //element of results[] to store the output 
            linear_idx = gidz * ALPSIZE_TO2 + gidy * ALPSIZE + gidx;
            result = &taskResults[linear_idx];
            result->index = linear_idx;
            result->score = -1;
            // linear_idx = gid
            // results set later ant return
          } */
        s_waitcnt lgkmcnt(0)

.macro ComputeScramblerIndexNextV char_pos, scramblerIndex
        ########################
        # next part
        ########################
        v_cmp_eq_u32 vcc, \char_pos, 0
        s_sub_u32 canInc_l_phase, 0, canInc_l_phase
        s_and_b32 vcc_lo, canInc_l_phase, vcc_lo
        s_and_b32 vcc_hi, canInc_l_phase, vcc_hi
        VRegAlloc1 l_phase_v
        v_mov_b32 l_phase_v, l_phase
        VADDC_U32 l_phase_v, vcc, 0, l_phase_v, vcc
        /* int m_steps = (m_phase + char_pos + 1) / m_period; */
        VRegAlloc1 m_steps
        VADD_U32 m_steps, vcc, m_phase, \char_pos
        VADD_U32 m_steps, vcc, 1, m_steps
        s_cmp_eq_i32 m_period, HALF_ALPSIZE
        #RegFree m_period
        #RegFree m_phase
        v_lshlrev_b32 m_steps, scc, m_steps
        VSDivBy26 m_steps, m_steps
        /* int l_steps = (l_phase + char_pos + 1) / l_period; */
        VRegAlloc1 l_steps
        VADD_U32 l_steps, vcc, l_phase_v, \char_pos
        VADD_U32 l_steps, vcc, 1, l_steps
        s_cmp_eq_i32 m_period, HALF_ALPSIZE
        RegFree l_phase_v
        #RegFree l_period
        #RegFree l_phase
        v_lshlrev_b32 l_steps, scc, l_steps
        VSDivByX l_steps, l_steps, l_period_const1, l_period_const2
        
        VADD_U32 m_steps, vcc, m_steps, l_steps
        
        # mod26(sett->l_mesg - sett->l_ring /*0*/ + l_steps)
        VADD_U32 l_steps, vcc, l_mesg, l_steps
        VMod26Fn l_steps, l_steps
        v_mul_i32_i24 l_steps, ALPSIZE_TO2, l_steps
        
        # mod26(sett->m_mesg - sett->m_ring + m_steps)
        VADD_U32 m_steps, vcc, m_mesg, m_steps
        VSUB_U32 m_steps, vcc, m_steps, mr_ring[0]
        VMod26Fn m_steps, m_steps
        v_mul_i32_i24 m_steps, ALPSIZE, m_steps
        
        VADD_U32 \scramblerIndex, vcc, r_mesg, \char_pos
        VSUB_U32 \scramblerIndex, vcc, \scramblerIndex, mr_ring[1]
        VADD_U32 \scramblerIndex, vcc, 1, \scramblerIndex
        VMod26Fn \scramblerIndex, \scramblerIndex
        VADD_U32 \scramblerIndex, vcc, \scramblerIndex, m_steps
        VADD_U32 \scramblerIndex, vcc, \scramblerIndex, l_steps
        
        RegFree l_steps
        RegFree m_steps
.endm

    /*
     *---------------------------------
     * ToProcess
     * ---------------------
     */
        
        v_cmpx_gt_u32 vcc, TASK_SIZE, lid
        SRegAlloc2A taskSizeExec
        s_mov_b64 taskSizeExec, exec
        
        s_add_u32 tempClimbData[0], tempClimbData[0], gid48
        s_addc_u32 tempClimbData[1], tempClimbData[1], 0
        RegFree gid48
        
        SRegAlloc4A compScData0
        SRegAlloc4A compScData1
        SRegAlloc1 compScData2
        l_period_const1 = %compScData0[0]
        l_period_const2 = %compScData0[1]
        l_phase = %compScData0[2]
        m_period = %compScData0[3]
        m_phase = %compScData1[0]
        canInc_l_phase = %compScData1[1]
        l_mesg = %compScData1[2]
        m_mesg = %compScData1[3]
        r_mesg = %compScData2[0]
        
        s_load_dwordx4 compScData0, tempClimbData, 1*SMUL
        s_load_dwordx4 compScData1, tempClimbData, 5*SMUL
        s_load_dword compScData2, tempClimbData, 9*SMUL
        RegFree tempClimbData
        s_waitcnt lgkmcnt(0)
        
        /*  if (lid < block.count)
            {
                g_scrambling_table = scramblerData + 
                ComputeScramblerIndex(lid, &(d_key->stru), &sett, d_wiring) * 
                    scramblerDataPitch; */
        VRegAlloc1 scramblerIndex
        ComputeScramblerIndexNextV lid, scramblerIndex
        v_mul_u32_u24 scramblerIndex, SCRAMBLER_PITCH, scramblerIndex
        #ComputeScramblerIndexFree
        RegFree compScData0
        RegFree compScData1
        RegFree compScData2
        /* scrambling_table = ScramblerToShared(g_scrambling_table,
                        shared_scrambling_table, lid); */
        
        /* //global: ALPSIZE bytes at sequential addresses
            const global int32_t * src = (const global int32_t *)(global_scrambling_table);
        */
        
        # load scramblerData
        # load d_ciphertext
    .if AMDCL2_OR_GALLIUM
        .ifeq ADDRBITS-32
            SRegAlloc1 scramblerData
            SRegAlloc1 d_ciphertext
            s_load_dword scramblerData, argsPtr, scramblerData_arg*SMUL
            s_load_dword d_ciphertext, argsPtr, d_ciphertext_arg*SMUL
        .else
            SRegAlloc4A scramblerData_res
            SRegAlloc2A d_ciphertext
            s_load_dwordx2 scramblerData_res[0:1], argsPtr, scramblerData_arg*SMUL
            s_movk_i32 scramblerData_res[2], 0xffff
            s_mov_b32 scramblerData_res[3], 0x8027fac
            SRegAlloc4A d_ciphertext_res
            s_load_dwordx2 d_ciphertext_res[0:1], argsPtr, d_ciphertext_arg*SMUL
            s_mov_b64 d_ciphertext_res[2:3], scramblerData_res[2:3]
        .endif
    .elseiffmt amd
        SRegAlloc4A scramblerData_res
        SRegAlloc4A d_ciphertext_res
        s_load_dwordx4 scramblerData_res, uavTablePtr, SMUL*8*scramblerData_uav
        s_load_dwordx4 d_ciphertext_res, uavTablePtr, SMUL*8*d_ciphertext_uav
        .ifeq ADDRBITS-32
            SRegAlloc1 scramblerData
            SRegAlloc1 d_ciphertext
            s_buffer_load_dword scramblerData, constBuf1Res, SMUL*scramblerData_arg
            s_buffer_load_dword d_ciphertext, constBuf1Res, SMUL*d_ciphertext_arg
        .else
            SRegAlloc2A scramblerData
            SRegAlloc2A d_ciphertext
            s_buffer_load_dwordx2 scramblerData, constBuf1Res, SMUL*scramblerData_arg
            s_buffer_load_dwordx2 d_ciphertext, constBuf1Res, SMUL*d_ciphertext_arg
        .endif
    .endif
        s_waitcnt lgkmcnt(0)
        #prepare scramblerData
        VRegAlloc1 voffset
        voffset = %scramblerIndex
        
        VRegAlloc4 tmpv0_4
        VRegAlloc4 tmpv1_3
        VRegAlloc1 cipherLetter
    .if AMDCL2_OR_GALLIUM
        .ifeq ADDRBITS-32
            buffer_load_dwordx4 tmpv0_4, voffset, bufres, scramblerData offen
            buffer_load_dwordx3 tmpv1_3[0:2], voffset, bufres, scramblerData offen offset:16
            buffer_load_sbyte cipherLetter, lid, bufres, d_ciphertext offen
            RegFree scramblerData
            RegFree d_ciphertext
        .else
            buffer_load_dwordx4 tmpv0_4, voffset, scramblerData_res, 0 offen
        .ifeq ARCH-GCN10
            tbuffer_load_format_xyz tmpv1_3[0:2], voffset, scramblerData_res, 16 \
                offen format:[32_32_32,float]
        .else
            buffer_load_dwordx3 tmpv1_3[0:2], voffset, scramblerData_res, 16 offen
        .endif
            buffer_load_sbyte cipherLetter, lid, d_ciphertext_res, 0 offen
            RegFree scramblerData_res
            RegFree d_ciphertext_res
        .endif
    .elseiffmt amd
        .ifeq ADDRBITS-32
            buffer_load_dwordx4 tmpv0_4, voffset, scramblerData_res, scramblerData offen
            tbuffer_load_format_xyz tmpv1_3[0:2], voffset, scramblerData_res, \
                        scramblerData offen offset:16 format:[32_32_32,float]
            buffer_load_sbyte cipherLetter, lid, d_ciphertext_res, d_ciphertext offen
        .else
            s_add_u32 scramblerData_res[0], scramblerData_res[0], scramblerData[0]
            s_addc_u32 scramblerData_res[1], scramblerData_res[1], scramblerData[1]
            buffer_load_dwordx4 tmpv0_4, voffset, scramblerData_res, 0 offen
            tbuffer_load_format_xyz tmpv1_3[0:2], voffset, scramblerData_res, 0 \
                    offen offset:16 format:[32_32_32,float]
            s_add_u32 d_ciphertext_res[0], d_ciphertext_res[0], d_ciphertext[0]
            s_addc_u32 d_ciphertext_res[1], d_ciphertext_res[1], d_ciphertext[1]
            buffer_load_sbyte cipherLetter, lid, d_ciphertext_res, 0 offen
        .endif
        RegFree scramblerData
        RegFree d_ciphertext
        RegFree scramblerData_res
        RegFree d_ciphertext_res
    .endif
    
        # prepare d_order ptr
    .if AMDCL2_OR_GALLIUM
        .ifeq ADDRBITS-32
            SRegAlloc1 d_order
            s_load_dword d_order, argsPtr, SMUL*d_order_arg
        .else
        .ifeq ARCH-GCN10
            SRegAlloc4A d_order
        .else
            SRegAlloc2A d_order
        .endif
            s_load_dwordx2 d_order[0:1], argsPtr, SMUL*d_order_arg
        .endif
    .elseiffmt amd
        SRegAlloc4A d_order_res
        s_load_dwordx4 d_order_res, uavTablePtr, SMUL*8*d_order_uav
        .ifeq ADDRBITS-32
            SRegAlloc1 d_order
            s_buffer_load_dword d_order, constBuf1Res, SMUL*d_order_arg
        .else
            SRegAlloc2A d_order
            s_buffer_load_dwordx2 d_order, constBuf1Res, SMUL*d_order_arg
        .endif
    .endif
        RegFree scramblerIndex
        VRegAlloc1 dsoffset
        
        /*  //copy ALPSIZE bytes as 7 x 32-bit words
            int idx = (lid & ~(SCRAMBLER_STRIDE-1)) * 7 + (lid & (SCRAMBLER_STRIDE-1));
            for (int i = 0; i < 7; ++i) dst[idx + SCRAMBLER_STRIDE * i] = src[i];
            return &shared_scrambling_table[idx * 4]; */
        
        v_and_b32 dsoffset, ~(SCRAMBLER_STRIDE-1)<<2, lid4
        v_mul_u32_u24 dsoffset, 7, dsoffset
        v_bfi_b32 dsoffset, (SCRAMBLER_STRIDE-1)<<2, lid4, dsoffset
        VADD_U32 dsoffset, vcc, LocalScrambler, dsoffset
        
        s_waitcnt lgkmcnt(0)
        
        VRegAlloc1 d_orderVal
        s_mov_b64 exec, -1
        v_and_b32 d_orderVal, 63, lid
        v_cmpx_gt_u32 vcc, ALPSIZE, d_orderVal
    
        # load d_order to
    .if AMDCL2_OR_GALLIUM
        .ifeq ADDRBITS-32
            buffer_load_sbyte d_orderVal, d_orderVal, bufres, d_order offen
        .else
        .ifeq ARCH-GCN10
            s_movk_i32 d_order[2], 0xffff
            s_mov_b32 d_order[3], 0x8027fac
            buffer_load_sbyte d_orderVal, d_orderVal, d_order, 0 offen
        .else
            VRegAlloc2 tmpaddr
            VADD_U32 tmpaddr[0], vcc, d_order[0], d_orderVal
            v_mov_b32 tmpaddr[1], d_order[1]
            VADDC_U32 tmpaddr[1], vcc, 0, tmpaddr[1], vcc
            flat_load_sbyte d_orderVal, tmpaddr
            RegFree tmpaddr
        .endif
        .endif
        RegFree d_order
    .elseiffmt amd
        .ifeq ADDRBITS-32
            buffer_load_sbyte d_orderVal, d_orderVal, d_order_res, d_order offen
        .else
            s_add_u32 d_order_res[0], d_order_res[0], d_order[0]
            s_addc_u32 d_order_res[1], d_order_res[1], d_order[1]
            buffer_load_sbyte d_orderVal, d_orderVal, d_order_res, 0 offen
        .endif
        RegFree d_order
        RegFree d_order_res
    .endif
        s_waitcnt vmcnt(3)
        
        s_mov_b64 exec, taskSizeExec
    
        ds_write2_b32 dsoffset, tmpv0_4[0], tmpv0_4[1] offset1:SCRAMBLER_STRIDE
        ds_write2_b32 dsoffset, tmpv0_4[2], tmpv0_4[3] \
                    offset0:SCRAMBLER_STRIDE*2  offset1:SCRAMBLER_STRIDE*3
        
        s_waitcnt vmcnt(2)
        ds_write2_b32 dsoffset, tmpv1_3[0], tmpv1_3[1] \
                    offset0:SCRAMBLER_STRIDE*4 offset1:SCRAMBLER_STRIDE*5
        ds_write_b32 dsoffset, tmpv1_3[2] offset:SCRAMBLER_STRIDE*4*6
        
        RegFree tmpv0_4
        RegFree tmpv1_3
        #RegFree dsoffset
        #dsoffset - offset to local scrambler
        SRegAlloc1 d_fixed
    .if AMDCL2_OR_GALLIUM
        s_load_dword d_fixed, argsPtr, SMUL*d_fixed_arg
    .elseiffmt amd
        s_buffer_load_dword d_fixed, constBuf1Res, SMUL*d_fixed_arg
    .endif
        s_waitcnt lgkmcnt(0) & vmcnt(0)
        # LocalTemps/LocalScoreBuf condition race fix
        Barrier
        
    /*
     ********************************************
     Main computing routines
     ***************************************************
     */
    
        VRegAlloc1 cv
        VRegAlloc1 cvaddr
        VRegAlloc1 vone
    .macro Decode
        ds_read_i8 cv, cipherLetter offset:LocalPlugs
        s_waitcnt lgkmcnt(0)
        v_and_b32 cvaddr, ~3, cv
        v_mul_u32_u24 cvaddr, SCRAMBLER_STRIDE, cvaddr
        v_bfi_b32 cvaddr, 3, cv, cvaddr
        VADD_U32 cvaddr, vcc, cvaddr, dsoffset
        ds_read_i8 cv, cvaddr
        s_waitcnt lgkmcnt(0)
        ds_read_i8 cv, cv offset:LocalPlugs
        s_waitcnt lgkmcnt(0)
    .endm
    
        SRegAlloc1 i_s
        SRegAlloc1 k_s
    .if USE_LOCAL_IN_TRYSWAP
        VRegAlloc1 i_v
        VRegAlloc1 k_v
        VRegAlloc1 x_v
        VRegAlloc1 z_v
    .else
        SRegAlloc1 x_s
        SRegAlloc1 z_s
    .endif
        SRegAlloc1 old_score
.macro TrySwap CalculateScore
        # HINT!:
        # use Vector register to manipulate d_plugs, store to LDS only if needed
        v_readlane_b32 i_s, d_orderVal, p_s
        v_readlane_b32 k_s, d_orderVal, q_s
        
        s_bitcmp1_b32 d_fixed, i_s
        s_cbranch_scc1 TrySwapEnd\@
        s_bitcmp1_b32 d_fixed, k_s
        s_cbranch_scc1 TrySwapEnd\@
        
        s_mov_b64 exec, -1
        v_cmpx_eq_u32 vcc, 0, lid
        .ifgt TASK_SIZE-64
            s_cbranch_execz TrySwapSkipLidNe0\@
        .endif
        
        s_mov_b32 old_score, score
        
    .if USE_LOCAL_IN_TRYSWAP
    
        VRegAlloc1 i2_v
    
        v_mov_b32 i_v, i_s
        v_mov_b32 k_v, k_s
        ds_read_i8 x_v, i_v offset:LocalPlugs
        ds_read_i8 z_v, k_v offset:LocalPlugs
        
        s_waitcnt lgkmcnt(1)
        v_cmp_eq_i32 vcc, x_v, k_v
        v_cndmask_b32 i2_v, k_v, i_v, vcc
        ds_write_b8 i_v, i2_v offset:LocalPlugs
        v_cndmask_b32 i2_v, i_v, k_v, vcc
        ds_write_b8 k_v, i2_v offset:LocalPlugs
        
        RegFree i2_v
        
        s_cbranch_vccnz TrySwapCompSkip\@
        v_cmp_ne_i32 vcc, x_v, i_v
        s_cbranch_vccz TrySwapCompSkipX\@
        ds_write_b8 x_v, x_v offset:LocalPlugs
TrySwapCompSkipX\@:
        s_waitcnt lgkmcnt(2)
        v_cmp_ne_i32 vcc, z_v, k_v
        s_cbranch_vccz TrySwapCompSkipZ\@
        ds_write_b8 z_v, z_v offset:LocalPlugs
TrySwapCompSkipZ\@:
TrySwapCompSkip\@:
        s_waitcnt lgkmcnt(0)
        
    .else # USE_LOCAL_IN_TRYSWAP = 0
    
        /*  x = block->plugs[i];
            z = block->plugs[k];
            if (x != k)
            {
                block->plugs[x] = (x != i) ? x : block->plugs[x];
                block->plugs[z] = (z != k) ? z : block->plugs[z];
            }
            block->plugs[i] = (x==k) ? i : k;
            block->plugs[k] = (x==k) ? k : i;
        */
        
        SRegAlloc1 i2_s
        SRegAlloc1 k2_s
        v_readlane_b32 x_s, d_plugsVal, i_s
        v_readlane_b32 z_s, d_plugsVal, k_s
        
        s_cmp_eq_i32 x_s, k_s
        s_cselect_b32 i2_s, i_s, k_s
        s_lshl_b32 exec_lo, 1, i_s
        v_mov_b32 d_plugsVal, i2_s
        s_cselect_b32 k2_s, k_s, i_s
        s_lshl_b32 exec_lo, 1, k_s
        v_mov_b32 d_plugsVal, k2_s
        RegFree k2_s
        
        SRegAlloc1 tmps2
        s_cbranch_scc1 TrySwapCompSkip\@
        v_readlane_b32 tmps2, d_plugsVal, x_s
        s_cmp_lg_i32 x_s, i_s
        s_cselect_b32 i2_s, x_s, tmps2
        s_lshl_b32 exec_lo, 1, x_s
        v_mov_b32 d_plugsVal, i2_s
        v_readlane_b32 tmps2, d_plugsVal, z_s
        s_cmp_lg_i32 z_s, k_s
        s_cselect_b32 i2_s, z_s, tmps2
        s_lshl_b32 exec_lo, 1, z_s
        v_mov_b32 d_plugsVal, i2_s
        RegFree i2_s
        RegFree tmps2
TrySwapCompSkip\@:
        
        ds_write_b8 lid, d_plugsVal offset:LocalPlugs
        s_waitcnt lgkmcnt(0)
    .endif #USE_LOCAL_IN_TRYSWAP
    
    .ifgt TASK_SIZE-64
TrySwapSkipLidNe0\@:
    .endif
        Barrier
        
        \CalculateScore
        
        s_mov_b64 exec, -1
    .if USE_LOCAL_IN_TRYSWAP
        v_cmpx_eq_u32 vcc, 0, lid
        s_cbranch_execz TrySwapSkipLast\@
        s_cmp_le_i32 score, old_score
        s_cbranch_scc0 TrySwapSkipLast\@
        s_mov_b32 score, old_score
        ds_write_b8 z_v, k_v offset:LocalPlugs
        ds_write_b8 x_v, i_v offset:LocalPlugs
        ds_write_b8 k_v, z_v offset:LocalPlugs
        ds_write_b8 i_v, x_v offset:LocalPlugs
        s_waitcnt lgkmcnt(0)
    .else
        v_cmpx_eq_u32 vcc, z_s, lid
        s_cbranch_execz TrySwapSkipLast\@
        s_cmp_le_i32 score, old_score
        s_cbranch_scc0 TrySwapSkipLast\@
        s_mov_b32 score, old_score
        v_mov_b32 d_plugsVal, k_s
        s_lshl_b32 exec_lo, 1, x_s
        v_mov_b32 d_plugsVal, i_s
        s_lshl_b32 exec_lo, 1, k_s
        v_mov_b32 d_plugsVal, z_s
        s_lshl_b32 exec_lo, 1, i_s
        v_mov_b32 d_plugsVal, x_s
    .endif
TrySwapSkipLast\@:
        Barrier
    /*.if DEBUG && CUR_SCORE_KIND==skTrigram
        s_cmp_eq_u32 loopCount, DUMP_IN_LOOPCOUNT
        s_cbranch_scc0 tryswapNoThisCount_\@
        v_cmp_eq_u32 vcc, 0, lid
        s_cbranch_vccz tryswapstop_\@
        #ds_read_i8 i_v, x_v offset:LocalPlugs
        #s_waitcnt lgkmcnt(0)
        DUMP_SREG score
tryswapstop_\@: s_endpgm
tryswapNoThisCount_\@:
        s_add_u32 loopCount, loopCount, 1
        s_branch tryswapAfter\@
    .endif*/
TrySwapEnd\@:
    /*.if DEBUG && CUR_SCORE_KIND==skTrigram
        s_cmp_eq_u32 loopCount, DUMP_IN_LOOPCOUNT
        s_cbranch_scc0 tryswapNoThisCount\@
        v_cmp_eq_u32 vcc, 0, lid
        s_cbranch_vccz tryswapstop\@
        DUMP_SREG score
tryswapstop\@: s_endpgm
tryswapNoThisCount\@:
        s_add_u32 loopCount, loopCount, 1
tryswapAfter\@:
    .endif*/
.endm
    DUMP_IN_LOOPCOUNT = 267
    
    LOOP_ITERS_NUM = (ALPSIZE-1)*(ALPSIZE>>1)
    
    SRegAlloc1 score
    SRegAlloc1 p_s
    SRegAlloc1 q_s
    SRegAlloc1 loopi_s
.if DEBUG
    SRegAlloc1 loopCount
.endif
    
    /***************************
     * IcScore
     ***********************/
.ifne SCORE_KINDS&skIC
CUR_SCORE_KIND = skIC

    HISTO_SIZE = 32
    .macro IcScore
        s_mov_b64 exec, -1
        v_cmpx_gt_u32 vcc, HISTO_SIZE, lid
        .ifgt TASK_SIZE-64
            s_cbranch_execz IcScore_skip1_\@
        .endif
        v_mov_b32 vone, 0
        /*  //init histogram
            if (lid < HISTO_SIZE) block->score_buf[lid] = 0;
            barrier(CLK_LOCAL_MEM_FENCE); */
        ds_write_b32 lid4, vone offset:LocalScoreBuf
        s_waitcnt lgkmcnt(0)
IcScore_skip1_\@:
        Barrier
        
        /*  //compute histogram
            if (lid < block->count)
            {
                int8_t c = Decode(block->plugs, scrambling_table, d_ciphertext, lid);
                //atomicAdd((int *)&block->score_buf[c], 1);
                atomic_add(&block->score_buf[c], 1);
            }
            barrier(CLK_LOCAL_MEM_FENCE);
        */
        s_mov_b64 exec, taskSizeExec
        Decode
        v_lshlrev_b32 cv, 2, cv
        v_mov_b32 vone, 1
        ds_add_u32 cv, vone offset:LocalScoreBuf
        s_waitcnt lgkmcnt(0)
        Barrier
        v_cmpx_gt_u32 vcc, HISTO_SIZE, lid
        s_cbranch_execz IcScore_skip2_\@
        
        /*  //TODO: try lookup table here, ic[MAX_MESSAGE_LENGTH]
            if (lid < HISTO_SIZE)
                block->score_buf[lid] *= block->score_buf[lid] - 1;
        */
        ds_read_b32 vone, lid4 offset:LocalScoreBuf
        s_waitcnt lgkmcnt(0)
        VSUBREV_U32 cvaddr, vcc, 1, vone
        v_mul_u32_u24 vone, vone, cvaddr
        # summarize
        /* //sum up
            if (lid < (HISTO_SIZE >> 1))
            {
                block->score_buf[lid] += block->score_buf[lid + 16];
                block->score_buf[lid] += block->score_buf[lid + 8];
                block->score_buf[lid] += block->score_buf[lid + 4];
                block->score_buf[lid] += block->score_buf[lid + 2];
                if (lid == 0) block->score = block->score_buf[0] + block->score_buf[1];
            }

            barrier(CLK_LOCAL_MEM_FENCE);
        */
        .ifge ARCH-GCN12
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_shr:1
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_shr:2
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_shr:4
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_shr:8
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_bcast:15
            v_readlane_b32  score, vone, 31
        .else   # GCN 1.0/1.1
            ds_swizzle_b32  cvaddr, vone offset:0x8031      # th3 -> th2, th1 -> th0
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, vone, cvaddr
            ds_swizzle_b32  cvaddr, vone offset:0x8002      # th2 -> th0
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, vone, cvaddr
            ds_swizzle_b32  cvaddr, vone offset:0x1f|(4<<5)      # th4 -> th0
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, vone, cvaddr
            ds_swizzle_b32  cvaddr, vone offset:0x1f|(8<<5)      # th8 -> th0
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, vone, cvaddr
            ds_swizzle_b32  cvaddr, vone offset:0x1f|(16<<5)      # th16 -> th0
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, vone, cvaddr
            v_readfirstlane_b32  score, vone
        .endif
IcScore_skip2_\@:
        Barrier
    .endm
        
        # CalculateScore(block, scrambling_table, d_ciphertext, d_bigrams, trigrams, lid);
        IcScore
        
        /*  for (int p = 0; p < ALPSIZE - 1; p++)
                for (int q = p + 1; q < ALPSIZE; q++) */
        s_mov_b32 p_s, 0
        s_mov_b32 q_s, 1
        s_movk_i32 loopi_s, (LOOP_ITERS_NUM / UNROLL_SIZE) - 1
.p2align 5
IcScoreMainLoop:
    .rept UNROLL_SIZE
        TrySwap IcScore
        
        s_add_u32 q_s, q_s, 1
        s_cmp_eq_u32 q_s, ALPSIZE
        s_cbranch_scc0 0f
        s_add_u32 p_s, p_s, 1
        s_add_u32 q_s, p_s, 1
0:
    .endr
        s_sub_u32 loopi_s, loopi_s, 1
        s_cbranch_scc0 IcScoreMainLoop
    # last loop iters
    .if (LOOP_ITERS_NUM % UNROLL_SIZE)
        .rept (LOOP_ITERS_NUM % UNROLL_SIZE)-1
            TrySwap IcScore
            
            s_add_u32 q_s, q_s, 1
            s_cmp_eq_u32 q_s, ALPSIZE
            s_cbranch_scc0 0f
            s_add_u32 p_s, p_s, 1
            s_add_u32 q_s, p_s, 1
0:
        .endr
        TrySwap IcScore
    .endif
    .ifeq DEBUG_PART-1
    .if DEBUG
        s_mov_b64 exec, -1
        v_cmp_eq_u32 vcc, 0, lid
        s_cbranch_vccz tryswapstopic
        DUMP_SREG score
tryswapstopic: s_endpgm
    .endif
    .endif
.endif
    
.ifne SCORE_KINDS&(skUnigram|skBigram|skTrigram)
    s_mov_b64 exec, -1
    .ifge ARCH-GCN12
        SRegAlloc2A lastWaveLane
        .ifgt TASK_SIZE-64
            SRegAlloc2A lastGroupLane
            s_mov_b32 lastWaveLane[0], 0
            s_mov_b32 lastWaveLane[1], 1<<31
            v_cmp_eq_u32 lastGroupLane, 63, lid
        .else
            lastGroupLane = %lastWaveLane
            s_mov_b32 lastGroupLane[0], 0
            s_mov_b32 lastGroupLane[1], 1<<31
        .endif
    .else
        SRegAlloc2A lastWaveLane
        .ifgt TASK_SIZE-64
            SRegAlloc2A firstGroupLane
            s_mov_b32 lastWaveLane[0], 0
            s_mov_b32 lastWaveLane[1], 1<<31
            v_cmp_eq_u32 firstGroupLane, 0, lid
        .else
            firstGroupLane = 1
            s_mov_b32 lastWaveLane[0], 0
            s_mov_b32 lastWaveLane[1], 1<<31
        .endif
    .endif
    
    
    VRegAlloc1 wvid4
    v_lshrrev_b32 wvid4, 4, lid
    v_and_b32 wvid4, 12, wvid4
    .ifgt TASK_SIZE-192
        VRegAlloc1 tmpsums0
        VRegAlloc2 tmpsums1
        tmpsums = %tmpsums1
    .elseifgt TASK_SIZE-128
        VRegAlloc2 tmpsums
    .elseifgt TASK_SIZE-64
        VRegAlloc1 tmpsums
    .endif
    
    .iflt ARCH-GCN12
        SRegAlloc1 tmpadd
    .endif
.endif #SCORE_KINDS&(skUnigram|skBigram|skTrigram)
    
    /****************************
      Loop for Unigrams
    ****************************/
.ifne SCORE_KINDS&skUnigram
CUR_SCORE_KIND = skUnigram
    
    .macro UniScore
        s_mov_b64 exec, -1
        v_mov_b32 vone, 0
        s_mov_b64 exec, taskSizeExec
        Decode
        
        v_lshlrev_b32 cv, 2, cv
        ds_read_b32 vone, cv offset:LocalUnigrams
        s_waitcnt lgkmcnt(0)
        
        s_mov_b64 exec, -1
        .ifge ARCH-GCN12
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_shr:1
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_shr:2
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_shr:4
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_shr:8
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_bcast:15
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_bcast:31
        .else   # GCN 1.0/1.1
            ds_swizzle_b32  cvaddr, vone offset:0x8031      # th3 -> th2, th1 -> th0
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, vone, cvaddr
            ds_swizzle_b32  cvaddr, vone offset:0x8002      # th2 -> th0
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, vone, cvaddr
            ds_swizzle_b32  cvaddr, vone offset:0x1f|(4<<5)      # th4 -> th0
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, vone, cvaddr
            ds_swizzle_b32  cvaddr, vone offset:0x1f|(8<<5)      # th8 -> th0
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, vone, cvaddr
            ds_swizzle_b32  cvaddr, vone offset:0x1f|(16<<5)      # th16 -> th0
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, vone, cvaddr
            v_readlane_b32  tmpadd, vone, 32        # get V4[32] (th32)
            VADD_U32       vone, vcc, tmpadd, vone
        .endif
    
        .ifgt TASK_SIZE-64
            # store
            .ifge ARCH-GCN12
                s_mov_b64       exec, lastWaveLane # enable last wavefront lane
                ds_write_b32    wvid4, vone offset:LocalTmpSums
            .else
                s_mov_b64       exec, 1 # enable first wavefront lane
                ds_write_b32    wvid4, vone offset:LocalTmpSums
            .endif
            s_waitcnt       lgkmcnt(0)
            Barrier
            .ifge ARCH-GCN12
                s_mov_b64       exec, lastGroupLane  # enable 63th lane in group
            .else
                s_mov_b64       exec, firstGroupLane
            .endif
            s_cbranch_execz Unisumskip\@
        .endif
                    
        .ifgt TASK_SIZE-192
            ds_read_b32     tmpsums0, wvid4 offset:LocalTmpSums+4
            ds_read_b64     tmpsums1, wvid4 offset:LocalTmpSums+8
            s_waitcnt       lgkmcnt(1)
            VADD_U32       vone, vcc, tmpsums0, vone
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, tmpsums1[0], vone
            VADD_U32       vone, vcc, tmpsums1[1], vone
Unisumskip\@:
        .elseifgt TASK_SIZE-128
            ds_read2_b32    tmpsums, wvid4 offset0:LocalTmpSums>>2+1 \
                    offset1:LocalTmpSums>>2+2
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, tmpsums[0], vone
            VADD_U32       vone, vcc, tmpsums[1], vone
Unisumskip\@:
        .elseifgt TASK_SIZE-64
            ds_read_b32     tmpsums, wvid4 offset:LocalTmpSums+4
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, tmpsums, vone
Unisumskip\@:
        .endif
        .ifge ARCH-GCN12
            v_readlane_b32 score, vone, 63
        .else
            v_readfirstlane_b32 score, vone
        .endif
        Barrier
    .endm
    
        UniScore
        
        s_mov_b32 p_s, 0
        s_mov_b32 q_s, 1
        s_movk_i32 loopi_s, (LOOP_ITERS_NUM / UNROLL_SIZE) - 1
    
UniScoreMainLoop:
    .rept UNROLL_SIZE
        TrySwap UniScore
        
        s_add_u32 q_s, q_s, 1
        s_cmp_eq_u32 q_s, ALPSIZE
        s_cbranch_scc0 0f
        s_add_u32 p_s, p_s, 1
        s_add_u32 q_s, p_s, 1
0:
    .endr
        s_sub_u32 loopi_s, loopi_s, 1
        s_cbranch_scc0 UniScoreMainLoop
    # last loop iters
    .if (LOOP_ITERS_NUM % UNROLL_SIZE)
        .rept (LOOP_ITERS_NUM % UNROLL_SIZE)-1
            TrySwap UniScore
            
            s_add_u32 q_s, q_s, 1
            s_cmp_eq_u32 q_s, ALPSIZE
            s_cbranch_scc0 0f
            s_add_u32 p_s, p_s, 1
            s_add_u32 q_s, p_s, 1
0:
        .endr
            TrySwap UniScore
    .endif
    .ifeq DEBUG_PART-2
    .if DEBUG
        s_mov_b64 exec, -1
        v_cmp_eq_u32 vcc, 0, lid
        s_cbranch_vccz tryswapstopuni
        DUMP_SREG score
tryswapstopuni: s_endpgm
    .endif
    .endif
    
.endif # SCORE_KINDS&skUnigram
    
    /***************************
     * Bigrams
     ***********************/
.ifne SCORE_KINDS&skBigram
CUR_SCORE_KIND = skBigram
    .if AMDCL2_OR_GALLIUM
        .ifeq ADDRBITS-32
            SRegAlloc1 d_bigrams
            s_load_dword d_bigrams, argsPtr, SMUL*d_bigrams_arg
        .else
            SRegAlloc4A d_bigrams_res
            s_load_dwordx2 d_bigrams_res[0:1], argsPtr, SMUL*d_bigrams_arg
            s_movk_i32 d_bigrams_res[2], 0xffff
            s_mov_b32 d_bigrams_res[3], 0x8027fac
        .endif
    .elseiffmt amd
        SRegAlloc4A d_bigrams_res
        s_load_dwordx4 d_bigrams_res, uavTablePtr, SMUL*8*d_bigrams_uav
        .ifeq ADDRBITS-32
            SRegAlloc1 d_bigrams
            s_buffer_load_dword d_bigrams, constBuf1Res, SMUL*d_bigrams_arg
        .else
            SRegAlloc2A d_bigrams
            s_buffer_load_dwordx2 d_bigrams, constBuf1Res, SMUL*d_bigrams_arg
        .endif
    .endif
        s_waitcnt lgkmcnt(0)
    
    .iffmt amd
        .ifeq ADDRBITS-64
            s_add_u32 d_bigrams_res[0], d_bigrams_res[0], d_bigrams[0]
            s_addc_u32 d_bigrams_res[1], d_bigrams_res[1], d_bigrams[1]
        .endif
    .endif
    
    .macro BiScore
        s_mov_b64 exec, -1
        v_mov_b32 vone, 0
        s_mov_b64 exec, taskSizeExec
        Decode
        ds_write_b8 lid, cv offset:LocalPlainText
        s_waitcnt lgkmcnt(0)
        Barrier
        
        v_cmpx_gt_u32 vcc, TASK_SIZE-1, lid 
    .if (TASK_SIZE&63)<=1 && (TASK_SIZE&63)!=0
        s_cbranch_execz BigramSkip2_\@
    .endif
        /* if (lid < (block->count - 1))
            block->score_buf[lid] = 
            d_bigrams[block->plain_text[lid]*ALPSIZE +
                    block->plain_text[lid + 1]]; */
        
        ds_read_i8 cvaddr, lid offset:LocalPlainText+1
        s_waitcnt lgkmcnt(0)
        
        v_mad_u32_u24 cvaddr, ALPSIZE, cv, cvaddr
    .if SHORT_BIGRAMS
        v_lshlrev_b32 cvaddr, 1, cvaddr
    .else
        v_lshlrev_b32 cvaddr, 2, cvaddr
    .endif
        
    .if SHORT_BIGRAMS
        .if AMDCL2_OR_GALLIUM
            .ifeq ADDRBITS-32
                buffer_load_ushort vone, cvaddr, bufres, d_bigrams offen
            .else
                buffer_load_ushort vone, cvaddr, d_bigrams_res, 0 offen
            .endif
        .elseiffmt amd
            .ifeq ADDRBITS-32
                buffer_load_ushort vone, cvaddr, d_bigrams_res, d_bigrams offen
            .else
                buffer_load_ushort vone, cvaddr, d_bigrams_res, 0 offen
            .endif
        .endif
    .else
        .if AMDCL2_OR_GALLIUM
            .ifeq ADDRBITS-32
                buffer_load_dword vone, cvaddr, bufres, d_bigrams offen
            .else
                buffer_load_dword vone, cvaddr, d_bigrams_res, 0 offen
            .endif
        .elseiffmt amd
            .ifeq ADDRBITS-32
                buffer_load_dword vone, cvaddr, d_bigrams_res, d_bigrams offen
            .else
                buffer_load_dword vone, cvaddr, d_bigrams_res, 0 offen
            .endif
        .endif
    .endif
        s_waitcnt vmcnt(0)
        s_mov_b64 exec, -1
        .ifge ARCH-GCN12
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_shr:1
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_shr:2
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_shr:4
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_shr:8
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_bcast:15
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_bcast:31
        .else   # GCN 1.0/1.1
            ds_swizzle_b32  cvaddr, vone offset:0x8031      # th3 -> th2, th1 -> th0
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, vone, cvaddr
            ds_swizzle_b32  cvaddr, vone offset:0x8002      # th2 -> th0
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, vone, cvaddr
            ds_swizzle_b32  cvaddr, vone offset:0x1f|(4<<5)      # th4 -> th0
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, vone, cvaddr
            ds_swizzle_b32  cvaddr, vone offset:0x1f|(8<<5)      # th8 -> th0
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, vone, cvaddr
            ds_swizzle_b32  cvaddr, vone offset:0x1f|(16<<5)      # th16 -> th0
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, vone, cvaddr
            v_readlane_b32  tmpadd, vone, 32        # get V4[32] (th32)
            VADD_U32       vone, vcc, tmpadd, vone
        .endif
    
        .ifgt TASK_SIZE-1-64
            # store
            .ifge ARCH-GCN12
                s_mov_b64       exec, lastWaveLane # enable last wavefront lane
                ds_write_b32    wvid4, vone offset:LocalTmpSums
            .else
                s_mov_b64       exec, 1 # enable first wavefront lane
                ds_write_b32    wvid4, vone offset:LocalTmpSums
            .endif
            s_waitcnt       lgkmcnt(0)
BigramSkip2_\@:
            Barrier
            .ifge ARCH-GCN12
                s_mov_b64       exec, lastGroupLane  # enable 63th lane in group
            .else
                s_mov_b64       exec, firstGroupLane
            .endif
            s_cbranch_execz Bisumskip\@
        .else
BigramSkip2_\@:
        .endif
        
        .ifgt TASK_SIZE-1-192
            ds_read_b32     tmpsums0, wvid4 offset:LocalTmpSums+4
            ds_read_b64     tmpsums1, wvid4 offset:LocalTmpSums+8
            s_waitcnt       lgkmcnt(1)
            VADD_U32       vone, vcc, tmpsums0, vone
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, tmpsums1[0], vone
            VADD_U32       vone, vcc, tmpsums1[1], vone
Bisumskip\@:
        .elseifgt TASK_SIZE-1-128
            ds_read2_b32    tmpsums, wvid4 offset0:LocalTmpSums>>2+1 \
                    offset1:LocalTmpSums>>2+2
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, tmpsums[0], vone
            VADD_U32       vone, vcc, tmpsums[1], vone
Bisumskip\@:
        .elseifgt TASK_SIZE-1-64
            ds_read_b32     tmpsums[0], wvid4 offset:LocalTmpSums+4
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, tmpsums[0], vone
Bisumskip\@:
        .endif
        .ifge ARCH-GCN12
            v_readlane_b32 score, vone, 63
        .else
            v_readfirstlane_b32 score, vone
        .endif
        Barrier
    .endm
    
        BiScore
        
        s_mov_b32 p_s, 0
        s_mov_b32 q_s, 1
    /*.if DEBUG
        s_mov_b32 loopCount, 0
    .endif*/
        s_movk_i32 loopi_s, (LOOP_ITERS_NUM / UNROLL_SIZE) - 1
    
BiScoreMainLoop:
    .rept UNROLL_SIZE
        TrySwap BiScore
        
        s_add_u32 q_s, q_s, 1
        s_cmp_eq_u32 q_s, ALPSIZE
        s_cbranch_scc0 0f
        s_add_u32 p_s, p_s, 1
        s_add_u32 q_s, p_s, 1
0:
    .endr
        s_sub_u32 loopi_s, loopi_s, 1
        s_cbranch_scc0 BiScoreMainLoop
    # last loop iters
    .if (LOOP_ITERS_NUM % UNROLL_SIZE)
        .rept (LOOP_ITERS_NUM % UNROLL_SIZE)-1
            TrySwap BiScore
            
            s_add_u32 q_s, q_s, 1
            s_cmp_eq_u32 q_s, ALPSIZE
            s_cbranch_scc0 0f
            s_add_u32 p_s, p_s, 1
            s_add_u32 q_s, p_s, 1
0:
        .endr
        TrySwap BiScore
    .endif
    .ifeq DEBUG_PART-3
    .if DEBUG
        s_mov_b64 exec, -1
        v_cmp_eq_u32 vcc, 0, lid
        s_cbranch_vccz tryswapstopbi
        DUMP_SREG score
tryswapstopbi: s_endpgm
    .endif
    .endif
    .iffmt amd
        RegFree d_bigrams
        RegFree d_bigrams_res
    .endif
    .if AMDCL2_OR_GALLIUM
        .ifeq ADDRBITS-32
            RegFree d_bigrams
        .else
            RegFree d_bigrams_res
        .endif
    .endif
.endif # SCORE_KINDS&skBigram
    
    /***************************
     * Trigrams
     ***********************/
.ifne SCORE_KINDS&skTrigram
CUR_SCORE_KIND = skTrigram
    .if AMDCL2_OR_GALLIUM
        .ifeq ADDRBITS-32
            SRegAlloc1 trigramsData
            s_load_dword trigramsData, argsPtr, SMUL*trigramsData_arg
        .else
            SRegAlloc4A trigramsData_res
            s_load_dwordx2 trigramsData_res[0:1], argsPtr, SMUL*trigramsData_arg
            s_movk_i32 trigramsData_res[2], 0xffff
            s_mov_b32 trigramsData_res[3], 0x8027fac
        .endif
    .elseiffmt amd
        SRegAlloc4A trigramsData_res
        s_load_dwordx4 trigramsData_res, uavTablePtr, SMUL*8*trigramsData_uav
        .ifeq ADDRBITS-32
            SRegAlloc1 trigramsData
            s_buffer_load_dword trigramsData, constBuf1Res, SMUL*trigramsData_arg
        .else
            SRegAlloc2A trigramsData
            s_buffer_load_dwordx2 trigramsData, constBuf1Res, SMUL*trigramsData_arg
        .endif
    .endif
        s_waitcnt lgkmcnt(0)
    
    .iffmt amd
        .ifeq ADDRBITS-64
            s_add_u32 trigramsData_res[0], trigramsData_res[0], trigramsData[0]
            s_addc_u32 trigramsData_res[1], trigramsData_res[1], trigramsData[1]
        .endif
    .endif
    
    VRegAlloc1 cvaddr2
    .macro TriScore
        s_mov_b64 exec, -1
        v_mov_b32 vone, 0
        s_mov_b64 exec, taskSizeExec
        Decode
        ds_write_b8 lid, cv offset:LocalPlainText
        s_waitcnt lgkmcnt(0)
        Barrier
    /*.if DEBUG
        ds_read_i8 cv, lid offset:LocalPlainText
        s_waitcnt lgkmcnt(0)
        s_not_b64 exec, exec
        v_mov_b32 cv, 0
        s_not_b64 exec, exec
        DUMP_VREG cv
    .endif*/
    
        /* if (lid < (block->count - 2))
            block->score_buf[lid] = trigrams[
            block->plain_text[lid] * ALPSIZE_TO2 +
            block->plain_text[lid + 1] * ALPSIZE +
            block->plain_text[lid+2]]; */
        
        v_cmpx_gt_u32 vcc, TASK_SIZE-2, lid
    .if (TASK_SIZE&63)<=2 && (TASK_SIZE&63)!=0
        s_cbranch_execz TrigramSkip2_\@
    .endif
        
        ds_read_i8 cvaddr, lid offset:LocalPlainText+1
        ds_read_i8 cvaddr2, lid offset:LocalPlainText+2
        s_waitcnt lgkmcnt(1)
        
        v_mad_u32_u24 cvaddr, ALPSIZE, cv, cvaddr
        s_waitcnt lgkmcnt(0)
    .if SHORT_TRIGRAMS
        v_mad_u32_u24 cvaddr, TRIGRAMS_PITCH>>1, cvaddr, cvaddr2
        v_lshlrev_b32 cvaddr, 1, cvaddr
    .else
        v_mad_u32_u24 cvaddr, TRIGRAMS_PITCH>>2, cvaddr, cvaddr2
        v_lshlrev_b32 cvaddr, 2, cvaddr
    .endif
    
    /*.if DEBUG
        s_not_b64 exec, exec
        v_mov_b32 cvaddr, 0
        s_not_b64 exec, exec
        DUMP_VREG cvaddr
    .endif*/
    
    .if SHORT_TRIGRAMS
        .if AMDCL2_OR_GALLIUM
            .ifeq ADDRBITS-32
                buffer_load_ushort vone, cvaddr, bufres, trigramsData offen
            .else
                buffer_load_ushort vone, cvaddr, trigramsData_res, 0 offen
            .endif
        .elseiffmt amd
            .ifeq ADDRBITS-32
                buffer_load_ushort vone, cvaddr, trigramsData_res, trigramsData offen
            .else
                buffer_load_ushort vone, cvaddr, trigramsData_res, 0 offen
            .endif
        .endif
    .else
        .if AMDCL2_OR_GALLIUM
            .ifeq ADDRBITS-32
                buffer_load_dword vone, cvaddr, bufres, trigramsData offen
            .else
                buffer_load_dword vone, cvaddr, trigramsData_res, 0 offen
            .endif
        .elseiffmt amd
            .ifeq ADDRBITS-32
                buffer_load_dword vone, cvaddr, trigramsData_res, trigramsData offen
            .else
                buffer_load_dword vone, cvaddr, trigramsData_res, 0 offen
            .endif
        .endif
    .endif
        s_waitcnt vmcnt(0)
    /*.if DEBUG
        DUMP_VREG vone
    .endif*/
        
        s_mov_b64 exec, -1
        .ifge ARCH-GCN12
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_shr:1
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_shr:2
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_shr:4
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_shr:8
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_bcast:15
            s_nop 1
            VADD_U32       vone, vcc, vone, vone row_bcast:31
        .else   # GCN 1.0/1.1
            ds_swizzle_b32  cvaddr, vone offset:0x8031      # th3 -> th2, th1 -> th0
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, vone, cvaddr
            ds_swizzle_b32  cvaddr, vone offset:0x8002      # th2 -> th0
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, vone, cvaddr
            ds_swizzle_b32  cvaddr, vone offset:0x1f|(4<<5)      # th4 -> th0
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, vone, cvaddr
            ds_swizzle_b32  cvaddr, vone offset:0x1f|(8<<5)      # th8 -> th0
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, vone, cvaddr
            ds_swizzle_b32  cvaddr, vone offset:0x1f|(16<<5)      # th16 -> th0
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, vone, cvaddr
            v_readlane_b32  tmpadd, vone, 32        # get V4[32] (th32)
            VADD_U32       vone, vcc, tmpadd, vone
        .endif
            
        .ifgt TASK_SIZE-2-64
            # store
            .ifge ARCH-GCN12
                s_mov_b64       exec, lastWaveLane # enable last wavefront lane
                ds_write_b32    wvid4, vone offset:LocalTmpSums
            .else
                s_mov_b64       exec, 1 # enable first wavefront lane
                ds_write_b32    wvid4, vone offset:LocalTmpSums
            .endif
            s_waitcnt       lgkmcnt(0)
TrigramSkip2_\@:
            Barrier
            .ifge ARCH-GCN12
                s_mov_b64       exec, lastGroupLane  # enable 63th lane in group
            .else
                s_mov_b64       exec, firstGroupLane
            .endif
            s_cbranch_execz Trisumskip\@
        .else
TrigramSkip2_\@:
        .endif
            
        .ifgt TASK_SIZE-2-192
            ds_read_b32     tmpsums0, wvid4 offset:LocalTmpSums+4
            ds_read_b64     tmpsums1, wvid4 offset:LocalTmpSums+8
            s_waitcnt       lgkmcnt(1)
            VADD_U32       vone, vcc, tmpsums0, vone
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, tmpsums1[0], vone
            VADD_U32       vone, vcc, tmpsums1[1], vone
Trisumskip\@:
        .elseifgt TASK_SIZE-2-128
            ds_read2_b32    tmpsums, wvid4 offset0:LocalTmpSums>>2+1 \
                    offset1:LocalTmpSums>>2+2
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, tmpsums[0], vone
            VADD_U32       vone, vcc, tmpsums[1], vone
Trisumskip\@:
        .elseifgt TASK_SIZE-2-64
            ds_read_b32     tmpsums[0], wvid4 offset:LocalTmpSums+4
            s_waitcnt       lgkmcnt(0)
            VADD_U32       vone, vcc, tmpsums[0], vone
Trisumskip\@:
        .endif
        .ifge ARCH-GCN12
            v_readlane_b32 score, vone, 63
        .else
            v_readfirstlane_b32 score, vone
        .endif
        Barrier
    .endm
    
        SRegAlloc1 old_score2
        VRegAlloc1 vzero
        s_mov_b64 exec, -1
        v_mov_b32 vzero, 0
        s_mov_b32 score, 0
.p2align 5
TriScoreDoWhile:
    
        s_mov_b32 old_score2, score
        TriScore
    /*.if DEBUG
        s_mov_b64 exec, -1
        v_cmp_ge_u32 vcc, 63, lid
        s_cbranch_vccz trisumend
        DUMP_SREG score
trisumend:s_endpgm
    .endif*/
        
        s_mov_b32 p_s, 0
        s_mov_b32 q_s, 1
    /*.if DEBUG
        s_mov_b32 loopCount, 0
    .endif*/
        s_movk_i32 loopi_s, (LOOP_ITERS_NUM / UNROLL_SIZE) - 1
    
TriScoreMainLoop:
    .rept UNROLL_SIZE
        TrySwap TriScore
        
        s_add_u32 q_s, q_s, 1
        s_cmp_eq_u32 q_s, ALPSIZE
        s_cbranch_scc0 0f
        s_add_u32 p_s, p_s, 1
        s_add_u32 q_s, p_s, 1
0:
    .endr
        s_sub_u32 loopi_s, loopi_s, 1
        s_cbranch_scc0 TriScoreMainLoop
    # last loop iters
    .if (LOOP_ITERS_NUM % UNROLL_SIZE)
        .rept (LOOP_ITERS_NUM % UNROLL_SIZE)-1
            TrySwap TriScore
            
            s_add_u32 q_s, q_s, 1
            s_cmp_eq_u32 q_s, ALPSIZE
            s_cbranch_scc0 0f
            s_addc_u32 p_s, p_s, 0
            s_add_u32 q_s, p_s, 1
0:
        .endr
        TrySwap TriScore
    .endif
    /*.if DEBUG
        s_mov_b64 exec, -1
        v_cmp_eq_u32 vcc, 0, lid
        s_cbranch_vccz tryswapstop
        DUMP_SREG score
tryswapstop: s_endpgm
    .endif*/
    
    .iffmt amd
        RegFree trigramsData
        RegFree trigramsData_res
    .endif
    .if AMDCL2_OR_GALLIUM
        .ifeq ADDRBITS-32
            RegFree trigramsData
        .else
            RegFree trigramsData_res
        .endif
    .endif
    RegFree cvaddr2
        s_cmp_gt_i32 score, old_score2
        s_mov_b64 exec, -1
        v_mov_b32 vone, scc
        v_cmpx_eq_u32 vcc, 0, lid
        ds_write_b32 vzero, vone offset:LocalOldScoreInd
        s_waitcnt lgkmcnt(0)
        Barrier
        s_mov_b64 exec, 1
        ds_read_b32 vone, vzero offset:LocalOldScoreInd
        s_waitcnt lgkmcnt(0)
        
        v_cmp_eq_u32 vcc, 1, vone
        s_cbranch_vccnz TriScoreDoWhile
        
        # final
    .ifeq DEBUG_PART-4
    .if DEBUG
        s_mov_b64 exec, -1
        v_cmp_eq_u32 vcc, 0, lid
        s_cbranch_vccz tryswapstoptri
        DUMP_SREG score
tryswapstoptri: s_endpgm
    .endif
    .endif
.endif # SCORE_KINDS&skTrigram

    RegFree p_s
    RegFree q_s
    RegFree loopi_s

.ifne SCORE_KINDS&(skUnigram|skBigram|skTrigram)
    RegFree wvid4
    .ifgt TASK_SIZE-192
        RegFree tmpsums0
        RegFree tmpsums1
    .elseifgt TASK_SIZE-128
        RegFree tmpsums
    .elseifgt TASK_SIZE-64
        RegFree tmpsums
    .endif
    .iflt ARCH-GCN12
        RegFree tmpadd
    .endif
.endif

    RegFree vone
    RegFree cv
    RegFree cvaddr

    .ifgt TASK_SIZE-64
        v_cmpx_eq_u32 vcc, 0, lid
        s_cbranch_execz skipWriteResults
    .endif
        
    .if AMDCL2_OR_GALLIUM
        .ifeq ADDRBITS-32
            SRegAlloc1 taskResults
            s_load_dword taskResults, argsPtr, SMUL*taskResults_arg
        .else # 64-bit
            SRegAlloc4A taskResults_res
            s_load_dwordx2 taskResults_res[0:1], argsPtr, SMUL*taskResults_arg
            s_movk_i32 taskResults_res[2], 0xffff
            s_mov_b32 taskResults_res[3], 0x8027fac
        .endif
    .elseiffmt amd
        SRegAlloc4A taskResults_res
        s_load_dwordx4 taskResults_res, uavTablePtr, SMUL*8*taskResults_uav
        .ifeq ADDRBITS-32
            SRegAlloc1 taskResults
            s_buffer_load_dword taskResults, constBuf1Res, SMUL*taskResults_arg
        .else
            SRegAlloc2A taskResults
            s_buffer_load_dwordx2 taskResults, constBuf1Res, SMUL*taskResults_arg
        .endif
    .endif
        s_waitcnt lgkmcnt(0)
        
        /* //copy plugboard solution to global results array;
            if (lid < ALPSIZE) result->plugs[lid] = block.plugs[lid];
            if (lid == 0) result->score = block.score; */
        s_mov_b64 exec, -1
        v_cmpx_gt_u32 vcc, ALPSIZE, lid
        # write plugs to score
    .ifne USE_LOCAL_IN_TRYSWAP
        VRegAlloc1 d_plugsVal
        ds_read_i8 d_plugsVal, lid offset:LocalPlugs
        s_waitcnt lgkmcnt(0)
    .endif
    SRegAlloc1 resultOffset
    .if AMDCL2_OR_GALLIUM
        .ifeq ADDRBITS-32
            s_mul_i32 resultOffset, gid, ResultSize
            s_add_u32 taskResults[0], taskResults[0], resultOffset
            buffer_store_byte d_plugsVal, lid, bufres, taskResults offen
        .else
            s_mul_i32 resultOffset, gid, ResultSize
            s_add_u32 taskResults_res[0], taskResults_res[0], resultOffset
            s_addc_u32 taskResults_res[1], taskResults_res[1], 0
            buffer_store_byte d_plugsVal, lid, taskResults_res, 0 offen
        .endif
    .elseiffmt amd
        s_mul_i32 resultOffset, gid, ResultSize
        s_add_u32 taskResults[0], taskResults[0], resultOffset
        .ifeq ADDRBITS-32
            buffer_store_byte d_plugsVal, lid, taskResults_res, taskResults offen
        .else
            s_addc_u32 taskResults[1], taskResults[1], 0
            s_add_u32 taskResults_res[0], taskResults_res[0], taskResults[0]
            s_addc_u32 taskResults_res[1], taskResults_res[1], taskResults[1]
            buffer_store_byte d_plugsVal, lid, taskResults_res, 0 offen
        .endif
    .endif
        
        s_mov_b64 exec, 1
        # write score and index
        VRegAlloc1At gidv, 1
        v_mov_b32 lid, score
        v_mov_b32 gidv, gid
    .if AMDCL2_OR_GALLIUM
        .ifeq ADDRBITS-32
            buffer_store_dwordx2 v[0:1], v0, bufres, taskResults offset:28
            RegFree taskResults
        .else
            buffer_store_dwordx2 v[0:1], v0, taskResults_res, 28
            RegFree taskResults_res
        .endif
    .elseiffmt amd
        .ifeq ADDRBITS-32
            buffer_store_dwordx2 v[0:1], v0, taskResults_res, taskResults offset:28
        .else
            buffer_store_dwordx2 v[0:1], v0, taskResults_res, 28
        .endif
        RegFree taskResults
        RegFree taskResults_res
    .endif
    .ifgt TASK_SIZE-64
skipWriteResults:
    .endif
    
        s_endpgm
.ends

.iffmt gallium
# special support for VEGA10 GPU (for GalliumCompute)
.ifeq GCN14-ARCH

.iflt LLVMVER-40000
.error "Unsupported LLVM version <4.0"
.endif

.kernel FindBestResultKernel
    .args
        .arg global, 8, 8, 8, zext, general
        .arg global, 8, 8, 8, zext, general
        .arg scalar, 4, 4, 4, zext, general
        .arg scalar, 4, 4, 4, zext, griddim
        .arg scalar, 4, 4, 4, zext, gridoffset
    .config
        .dims x
        .dx10clamp
        .ieeemode
        .floatmode 0xc0
        .priority 0
        .localsize 2048
        .userdatanum 8
        .use_private_segment_buffer
        .use_dispatch_ptr
        .use_kernarg_segment_ptr
        .private_elem_size 4
        .use_ptr64
.scope
.text
.p2align 8
::FindBestResultKernel:
.skip 256

# code from compilation of opencl_program.cl for Ellesmere (RX 480 device)
# Compile options: -DWITHOUT_CLIMB_KERNEL=1
# using Mesa3D 17.0.6/GalliumCompute Clover OpenCL implementation
# and LLVM/clang 4.0.1 compiler.
# disassembled by clrxdisasm 0.1.5r1
# only with substitutions different mnemonics for VEGA

/*000000000800: c0020002 00000004*/ s_load_dword    s0, s[4:5], 0x4
/*000000000808: c0020083 00000010*/ s_load_dword    s2, s[6:7], 0x10
/*000000000810: bf8c007f         */ s_waitcnt       lgkmcnt(0)
/*000000000814: 8604ff00 0000ffff*/ s_and_b32       s4, s0, 0xffff
/*00000000081c: 92000408         */ s_mul_i32       s0, s8, s4
/*000000000820: 8e008100         */ s_lshl_b32      s0, s0, 1
/*000000000824: 32060000         */ v_add_co_u32       v3, vcc, s0, v0
/*000000000828: 8100c102         */ s_add_i32       s0, s2, -1
/*00000000082c: 7e020200         */ v_mov_b32       v1, s0
/*000000000830: 7d980602         */ v_cmp_gt_u32    vcc, s2, v3
/*000000000834: 00020701         */ v_cndmask_b32   v1, v1, v3, vcc
/*000000000838: c0060003 00000000*/ s_load_dwordx2  s[0:1], s[6:7], 0x0
/*000000000840: d2850002 00014901*/ v_mul_lo_u32    v2, v1, 36
/*000000000848: d2860004 00014901*/ v_mul_hi_u32    v4, v1, 36
/*000000000850: bf8c007f         */ s_waitcnt       lgkmcnt(0)
/*000000000854: 32040400         */ v_add_co_u32       v2, vcc, s0, v2
/*000000000858: 7e0a0201         */ v_mov_b32       v5, s1
/*00000000085c: 380a0b04         */ v_addc_co_u32      v5, vcc, v4, v5, vcc
/*000000000860: 3208049c         */ v_add_co_u32       v4, vcc, 28, v2
/*000000000864: 380a0a80         */ v_addc_co_u32      v5, vcc, 0, v5, vcc
/*000000000868: dc500000 02000004*/ flat_load_dword v2, v[4:5]
/*000000000870: 32080604         */ v_add_co_u32       v4, vcc, s4, v3
/*000000000874: 7d980802         */ v_cmp_gt_u32    vcc, s2, v4
/*000000000878: be82206a         */ s_and_saveexec_b64 s[2:3], vcc
/*00000000087c: 8882027e         */ s_xor_b64       s[2:3], exec, s[2:3]
/*000000000880: bf8c0070         */ s_waitcnt       vmcnt(0) & lgkmcnt(0)
/*000000000884: bf880015         */ s_cbranch_execz .L2268_0
/*000000000888: d2860005 00014903*/ v_mul_hi_u32    v5, v3, 36
/*000000000890: d2850003 00014903*/ v_mul_lo_u32    v3, v3, 36
/*000000000898: 7e0c0201         */ v_mov_b32       v6, s1
/*00000000089c: d1080007 00014804*/ v_mul_u32_u24   v7, s4, 36
/*0000000008a4: 32060600         */ v_add_co_u32       v3, vcc, s0, v3
/*0000000008a8: 380a0d05         */ v_addc_co_u32      v5, vcc, v5, v6, vcc
/*0000000008ac: d1090006 00014804*/ v_mul_hi_u32_u24 v6, s4, 36
/*0000000008b4: 32060707         */ v_add_co_u32       v3, vcc, v7, v3
/*0000000008b8: 380c0d05         */ v_addc_co_u32      v6, vcc, v5, v6, vcc
/*0000000008bc: 320a069c         */ v_add_co_u32       v5, vcc, 28, v3
/*0000000008c0: 380c0c80         */ v_addc_co_u32      v6, vcc, 0, v6, vcc
/*0000000008c4: dc500000 03000005*/ flat_load_dword v3, v[5:6]
/*0000000008cc: bf8c0070         */ s_waitcnt       vmcnt(0) & lgkmcnt(0)
/*0000000008d0: 7d880503         */ v_cmp_gt_i32    vcc, v3, v2
/*0000000008d4: 1a040702         */ v_max_i32       v2, v2, v3
/*0000000008d8: 00020901         */ v_cndmask_b32   v1, v1, v4, vcc
.L2268_0:
/*0000000008dc: 87fe027e         */ s_or_b64        exec, exec, s[2:3]
/*0000000008e0: 24060083         */ v_lshlrev_b32   v3, 3, v0
/*0000000008e4: befc00c1         */ s_mov_b32       m0, -1
/*0000000008e8: d81c0100 00010203*/ ds_write2_b32   v3, v2, v1 offset1:1
/*0000000008f0: bf8c007f         */ s_waitcnt       lgkmcnt(0)
/*0000000008f4: bf8a0000         */ s_barrier
/*0000000008f8: c0060083 00000008*/ s_load_dwordx2  s[2:3], s[6:7], 0x8
/*000000000900: 8f048104         */ s_lshr_b32      s4, s4, 1
/*000000000904: bf068004         */ s_cmp_eq_u32    s4, 0
/*000000000908: be850080         */ s_mov_b32       s5, 0
/*00000000090c: bf8c007f         */ s_waitcnt       lgkmcnt(0)
/*000000000910: bf85001d         */ s_cbranch_scc1  .L2440_0
.L2324_0:
/*000000000914: 7d980004         */ v_cmp_gt_u32    vcc, s4, v0
/*000000000918: be86206a         */ s_and_saveexec_b64 s[6:7], vcc
/*00000000091c: 8886067e         */ s_xor_b64       s[6:7], exec, s[6:7]
/*000000000920: bf880014         */ s_cbranch_execz .L2420_0
/*000000000924: 8e058304         */ s_lshl_b32      s5, s4, 3
/*000000000928: 32080605         */ v_add_co_u32       v4, vcc, s5, v3
/*00000000092c: befc00c1         */ s_mov_b32       m0, -1
/*000000000930: d86c0000 04000004*/ ds_read_b32     v4, v4
/*000000000938: bf8c007f         */ s_waitcnt       lgkmcnt(0)
/*00000000093c: 7d880504         */ v_cmp_gt_i32    vcc, v4, v2
/*000000000940: be8a206a         */ s_and_saveexec_b64 s[10:11], vcc
/*000000000944: 888a0a7e         */ s_xor_b64       s[10:11], exec, s[10:11]
/*000000000948: 32020605         */ v_add_co_u32       v1, vcc, s5, v3
/*00000000094c: befc00c1         */ s_mov_b32       m0, -1
/*000000000950: d86c0004 01000001*/ ds_read_b32     v1, v1 offset:4
/*000000000958: 7e040304         */ v_mov_b32       v2, v4
/*00000000095c: bf8c007f         */ s_waitcnt       lgkmcnt(0)
/*000000000960: 87fe0a7e         */ s_or_b64        exec, exec, s[10:11]
/*000000000964: befc00c1         */ s_mov_b32       m0, -1
/*000000000968: d81c0100 00010203*/ ds_write2_b32   v3, v2, v1 offset1:1
/*000000000970: bf8c007f         */ s_waitcnt       lgkmcnt(0)
.L2420_0:
/*000000000974: 87fe067e         */ s_or_b64        exec, exec, s[6:7]
/*000000000978: bf8a0000         */ s_barrier
/*00000000097c: 8f048104         */ s_lshr_b32      s4, s4, 1
/*000000000980: bf068004         */ s_cmp_eq_u32    s4, 0
/*000000000984: bf84ffe3         */ s_cbranch_scc0  .L2324_0
.L2440_0:
/*000000000988: 7d940080         */ v_cmp_eq_u32    vcc, 0, v0
/*00000000098c: be84206a         */ s_and_saveexec_b64 s[4:5], vcc
/*000000000990: 8884047e         */ s_xor_b64       s[4:5], exec, s[4:5]
/*000000000994: bf88002a         */ s_cbranch_execz .L2624_0
/*000000000998: d2870000 00014901*/ v_mul_hi_i32    v0, v1, 36
/*0000000009a0: d2850001 00014901*/ v_mul_lo_u32    v1, v1, 36
/*0000000009a8: 7e040201         */ v_mov_b32       v2, s1
/*0000000009ac: d2860007 00014808*/ v_mul_hi_u32    v7, s8, 36
/*0000000009b4: 9201a408         */ s_mul_i32       s1, s8, 36
/*0000000009b8: 32080200         */ v_add_co_u32       v4, vcc, s0, v1
/*0000000009bc: 380a0500         */ v_addc_co_u32      v5, vcc, v0, v2, vcc
/*0000000009c0: dc5c0000 00000004*/ flat_load_dwordx4 v[0:3], v[4:5]
/*0000000009c8: 7e0c0201         */ v_mov_b32       v6, s1
/*0000000009cc: 7e100203         */ v_mov_b32       v8, s3
/*0000000009d0: 320c0c02         */ v_add_co_u32       v6, vcc, s2, v6
/*0000000009d4: 380e1107         */ v_addc_co_u32      v7, vcc, v7, v8, vcc
/*0000000009d8: 7e160280         */ v_mov_b32       v11, 0
/*0000000009dc: 321008a0         */ v_add_co_u32       v8, vcc, 32, v4
/*0000000009e0: 38121705         */ v_addc_co_u32      v9, vcc, v5, v11, vcc
/*0000000009e4: 32140ca0         */ v_add_co_u32       v10, vcc, 32, v6
/*0000000009e8: 38161707         */ v_addc_co_u32      v11, vcc, v7, v11, vcc
/*0000000009ec: 7e1c0280         */ v_mov_b32       v14, 0
/*0000000009f0: 32180890         */ v_add_co_u32       v12, vcc, 16, v4
/*0000000009f4: 381a1d05         */ v_addc_co_u32      v13, vcc, v5, v14, vcc
/*0000000009f8: 32080c90         */ v_add_co_u32       v4, vcc, 16, v6
/*0000000009fc: 380a1d07         */ v_addc_co_u32      v5, vcc, v7, v14, vcc
/*000000000a00: bf8c0070         */ s_waitcnt       vmcnt(0) & lgkmcnt(0)
/*000000000a04: dc7c0000 00000006*/ flat_store_dwordx4 v[6:7], v[0:3]
/*000000000a0c: bf8c0070         */ s_waitcnt       vmcnt(0) & lgkmcnt(0)
/*000000000a10: dc500000 00000008*/ flat_load_dword v0, v[8:9]
/*000000000a18: bf8c0070         */ s_waitcnt       vmcnt(0) & lgkmcnt(0)
/*000000000a1c: dc700000 0000000a*/ flat_store_dword v[10:11], v0
/*000000000a24: bf8c0070         */ s_waitcnt       vmcnt(0) & lgkmcnt(0)
/*000000000a28: dc5c0000 0000000c*/ flat_load_dwordx4 v[0:3], v[12:13]
/*000000000a30: bf8c0070         */ s_waitcnt       vmcnt(0) & lgkmcnt(0)
/*000000000a34: dc7c0000 00000004*/ flat_store_dwordx4 v[4:5], v[0:3]
/*000000000a3c: bf8c0070         */ s_waitcnt       vmcnt(0) & lgkmcnt(0)
.L2624_0:
/*000000000a40: 87fe047e         */ s_or_b64        exec, exec, s[4:5]
/*000000000a44: bf810000         */ s_endpgm
.ends

.kernel GenerateScramblerKernel
    .args
        .arg global, 8, 8, 8, zext, general
        .arg global, 8, 8, 8, zext, general
        .arg scalar, 4, 4, 4, zext, general
        .arg scalar, 4, 4, 4, zext, general
        .arg scalar, 4, 4, 4, zext, general
        .arg global, 8, 8, 8, zext, general
        .arg scalar, 4, 4, 4, zext, griddim
        .arg scalar, 4, 4, 4, zext, gridoffset
    .config
        .dims xyz
        .dx10clamp
        .ieeemode
        .floatmode 0xc0
        .priority 0
        .userdatanum 6
        .use_private_segment_buffer
        .use_kernarg_segment_ptr
        .private_elem_size 4
        .use_ptr64
.scope
.text
.p2align 8
::GenerateScramblerKernel:
.skip 256

# code from compilation of opencl_program.cl for Ellesmere (RX 480 device)
# Compile options: -DWITHOUT_CLIMB_KERNEL=1
# using Mesa3D 17.0.6/GalliumCompute Clover OpenCL implementation
# and LLVM/clang 4.0.1 compiler.
# disassembled by clrxdisasm 0.1.5r1
# only with substitutions different mnemonics for VEGA

/*000000000100: c0020082 00000010*/ s_load_dword    s2, s[4:5], 0x10
/*000000000108: c0020002 00000014*/ s_load_dword    s0, s[4:5], 0x14
/*000000000110: be810080         */ s_mov_b32       s1, 0
/*000000000114: bf8c007f         */ s_waitcnt       lgkmcnt(0)
/*000000000118: 81800200         */ s_sub_i32       s0, s0, s2
/*00000000011c: 86099f00         */ s_and_b32       s9, s0, 31
/*000000000120: 91008009         */ s_bfm_b32       s0, s9, 0
/*000000000124: 26020000         */ v_and_b32       v1, s0, v0
/*000000000128: 7d98029a         */ v_cmp_gt_u32    vcc, 26, v1
/*00000000012c: be80206a         */ s_and_saveexec_b64 s[0:1], vcc
/*000000000130: 8880007e         */ s_xor_b64       s[0:1], exec, s[0:1]
/*000000000134: bf88015c         */ s_cbranch_execz .L1704_0
/*000000000138: 86029f02         */ s_and_b32       s2, s2, 31
/*00000000013c: 8e020206         */ s_lshl_b32      s2, s6, s2
/*000000000140: 20000009         */ v_lshrrev_b32   v0, s9, v0
/*000000000144: 32000002         */ v_add_co_u32       v0, vcc, s2, v0
/*000000000148: d1c90000 02210100*/ v_bfe_i32       v0, v0, 0, 8
/*000000000150: d1c90002 02210101*/ v_bfe_i32       v2, v1, 0, 8
/*000000000158: c0060382 00000008*/ s_load_dwordx2  s[14:15], s[4:5], 0x8
/*000000000160: 32040102         */ v_add_co_u32       v2, vcc, v2, v0
/*000000000164: 320604b4         */ v_add_co_u32       v3, vcc, 52, v2
/*000000000168: 7e0402ff 4ec4ec4f*/ v_mov_b32       v2, 0x4ec4ec4f
/*000000000170: d2870004 00020503*/ v_mul_hi_i32    v4, v3, v2
/*000000000178: c0060282 00000000*/ s_load_dwordx2  s[10:11], s[4:5], 0x0
/*000000000180: c00200c2 00000018*/ s_load_dword    s3, s[4:5], 0x18
/*000000000188: c0060302 00000020*/ s_load_dwordx2  s[12:13], s[4:5], 0x20
/*000000000190: 200a089f         */ v_lshrrev_b32   v5, 31, v4
/*000000000194: bf8c007f         */ s_waitcnt       lgkmcnt(0)
/*000000000198: c0060107 00000010*/ s_load_dwordx2  s[4:5], s[14:15], 0x10
/*0000000001a0: 20080883         */ v_lshrrev_b32   v4, 3, v4
/*0000000001a4: 32080b04         */ v_add_co_u32       v4, vcc, v4, v5
/*0000000001a8: d2850004 00013504*/ v_mul_lo_u32    v4, v4, 26
/*0000000001b0: b0140082         */ s_movk_i32      s20, 0x82
/*0000000001b4: bf8c007f         */ s_waitcnt       lgkmcnt(0)
/*0000000001b8: d2860005 00013405*/ v_mul_hi_u32    v5, s5, 26
/*0000000001c0: 92069a05         */ s_mul_i32       s6, s5, 26
/*0000000001c4: 8015140a         */ s_add_u32       s21, s10, s20
/*0000000001c8: 36060704         */ v_subrev_co_u32    v3, vcc, v4, v3
/*0000000001cc: 7e0c0206         */ v_mov_b32       v6, s6
/*0000000001d0: 8206800b         */ s_addc_u32      s6, s11, 0
/*0000000001d4: 7e0e0206         */ v_mov_b32       v7, s6
/*0000000001d8: 320c0c15         */ v_add_co_u32       v6, vcc, s21, v6
/*0000000001dc: d1c90003 02210103*/ v_bfe_i32       v3, v3, 0, 8
/*0000000001e4: 380a0f05         */ v_addc_co_u32      v5, vcc, v5, v7, vcc
/*0000000001e8: 2208069f         */ v_ashrrev_i32   v4, 31, v3
/*0000000001ec: 32060706         */ v_add_co_u32       v3, vcc, v6, v3
/*0000000001f0: 38080905         */ v_addc_co_u32      v4, vcc, v5, v4, vcc
/*0000000001f4: dc400000 03000003*/ flat_load_ubyte v3, v[3:4]
/*0000000001fc: be821607         */ s_sext_i32_i8   s2, s7
/*000000000200: 8107b402         */ s_add_i32       s7, s2, 52
/*000000000204: d2860005 00013404*/ v_mul_hi_u32    v5, s4, 26
/*00000000020c: 92069a04         */ s_mul_i32       s6, s4, 26
/*000000000210: be881608         */ s_sext_i32_i8   s8, s8
/*000000000214: 8109b408         */ s_add_i32       s9, s8, 52
/*000000000218: c00a0407 00000000*/ s_load_dwordx4  s[16:19], s[14:15], 0x0
/*000000000220: bf8c007f         */ s_waitcnt       lgkmcnt(0)
/*000000000224: bf078310         */ s_cmp_lg_u32    s16, 3
/*000000000228: bf8c0f70         */ s_waitcnt       vmcnt(0)
/*00000000022c: 34060103         */ v_sub_co_u32       v3, vcc, v3, v0
/*000000000230: d1c90003 02210103*/ v_bfe_i32       v3, v3, 0, 8
/*000000000238: 32060607         */ v_add_co_u32       v3, vcc, s7, v3
/*00000000023c: d2870004 00020503*/ v_mul_hi_i32    v4, v3, v2
/*000000000244: 200c089f         */ v_lshrrev_b32   v6, 31, v4
/*000000000248: 20080883         */ v_lshrrev_b32   v4, 3, v4
/*00000000024c: 32080d04         */ v_add_co_u32       v4, vcc, v4, v6
/*000000000250: d2850004 00013504*/ v_mul_lo_u32    v4, v4, 26
/*000000000258: 7e0c0206         */ v_mov_b32       v6, s6
/*00000000025c: be860005         */ s_mov_b32       s6, s5
/*000000000260: 92059a13         */ s_mul_i32       s5, s19, 26
/*000000000264: 36060704         */ v_subrev_co_u32    v3, vcc, v4, v3
/*000000000268: 32080c15         */ v_add_co_u32       v4, vcc, s21, v6
/*00000000026c: d1c90003 02210103*/ v_bfe_i32       v3, v3, 0, 8
/*000000000274: 380a0b07         */ v_addc_co_u32      v5, vcc, v7, v5, vcc
/*000000000278: 220c069f         */ v_ashrrev_i32   v6, 31, v3
/*00000000027c: 32060704         */ v_add_co_u32       v3, vcc, v4, v3
/*000000000280: 38080d05         */ v_addc_co_u32      v4, vcc, v5, v6, vcc
/*000000000284: dc400000 03000003*/ flat_load_ubyte v3, v[3:4]
/*00000000028c: d2860005 00013413*/ v_mul_hi_u32    v5, s19, 26
/*000000000294: bf8c0070         */ s_waitcnt       vmcnt(0) & lgkmcnt(0)
/*000000000298: 36060602         */ v_subrev_co_u32    v3, vcc, s2, v3
/*00000000029c: d1c90003 02210103*/ v_bfe_i32       v3, v3, 0, 8
/*0000000002a4: 32060609         */ v_add_co_u32       v3, vcc, s9, v3
/*0000000002a8: d2870004 00020503*/ v_mul_hi_i32    v4, v3, v2
/*0000000002b0: 200c089f         */ v_lshrrev_b32   v6, 31, v4
/*0000000002b4: 20080883         */ v_lshrrev_b32   v4, 3, v4
/*0000000002b8: 32080d04         */ v_add_co_u32       v4, vcc, v4, v6
/*0000000002bc: d2850004 00013504*/ v_mul_lo_u32    v4, v4, 26
/*0000000002c4: 7e0c0205         */ v_mov_b32       v6, s5
/*0000000002c8: 36060704         */ v_subrev_co_u32    v3, vcc, v4, v3
/*0000000002cc: 32080c15         */ v_add_co_u32       v4, vcc, s21, v6
/*0000000002d0: d1c90003 02210103*/ v_bfe_i32       v3, v3, 0, 8
/*0000000002d8: 380a0b07         */ v_addc_co_u32      v5, vcc, v7, v5, vcc
/*0000000002dc: 220c069f         */ v_ashrrev_i32   v6, 31, v3
/*0000000002e0: 32060704         */ v_add_co_u32       v3, vcc, v4, v3
/*0000000002e4: 38080d05         */ v_addc_co_u32      v4, vcc, v5, v6, vcc
/*0000000002e8: dc400000 03000003*/ flat_load_ubyte v3, v[3:4]
/*0000000002f0: bf8c0070         */ s_waitcnt       vmcnt(0) & lgkmcnt(0)
/*0000000002f4: 36060608         */ v_subrev_co_u32    v3, vcc, s8, v3
/*0000000002f8: bf85005e         */ s_cbranch_scc1  .L1140_0
/*0000000002fc: c0020147 00000018*/ s_load_dword    s5, s[14:15], 0x18
/*000000000304: c0020387 00000028*/ s_load_dword    s14, s[14:15], 0x28
/*00000000030c: d1c90003 02210103*/ v_bfe_i32       v3, v3, 0, 8
/*000000000314: d2860004 00013412*/ v_mul_hi_u32    v4, s18, 26
/*00000000031c: 920f9a12         */ s_mul_i32       s15, s18, 26
/*000000000320: 7e0a020f         */ v_mov_b32       v5, s15
/*000000000324: bf8c007f         */ s_waitcnt       lgkmcnt(0)
/*000000000328: 8185050e         */ s_sub_i32       s5, s14, s5
/*00000000032c: be851705         */ s_sext_i32_i16  s5, s5
/*000000000330: 8105b405         */ s_add_i32       s5, s5, 52
/*000000000334: d2870006 00020405*/ v_mul_hi_i32    v6, s5, v2
/*00000000033c: 200e0c9f         */ v_lshrrev_b32   v7, 31, v6
/*000000000340: 220c0c83         */ v_ashrrev_i32   v6, 3, v6
/*000000000344: 320c0f06         */ v_add_co_u32       v6, vcc, v6, v7
/*000000000348: d2850006 00013506*/ v_mul_lo_u32    v6, v6, 26
/*000000000350: 340c0c05         */ v_sub_co_u32       v6, vcc, s5, v6
/*000000000354: 32060706         */ v_add_co_u32       v3, vcc, v6, v3
/*000000000358: 320606b4         */ v_add_co_u32       v3, vcc, 52, v3
/*00000000035c: d2870007 00020503*/ v_mul_hi_i32    v7, v3, v2
/*000000000364: 92059a11         */ s_mul_i32       s5, s17, 26
/*000000000368: 20100e9f         */ v_lshrrev_b32   v8, 31, v7
/*00000000036c: 200e0e83         */ v_lshrrev_b32   v7, 3, v7
/*000000000370: 320e1107         */ v_add_co_u32       v7, vcc, v7, v8
/*000000000374: d2850007 00013507*/ v_mul_lo_u32    v7, v7, 26
/*00000000037c: 7e10020b         */ v_mov_b32       v8, s11
/*000000000380: 36060707         */ v_subrev_co_u32    v3, vcc, v7, v3
/*000000000384: 320a0a0a         */ v_add_co_u32       v5, vcc, s10, v5
/*000000000388: d1c90003 02210103*/ v_bfe_i32       v3, v3, 0, 8
/*000000000390: 38121104         */ v_addc_co_u32      v9, vcc, v4, v8, vcc
/*000000000394: 220e069f         */ v_ashrrev_i32   v7, 31, v3
/*000000000398: 32060705         */ v_add_co_u32       v3, vcc, v5, v3
/*00000000039c: 38080f09         */ v_addc_co_u32      v4, vcc, v9, v7, vcc
/*0000000003a0: 32060614         */ v_add_co_u32       v3, vcc, s20, v3
/*0000000003a4: 38080880         */ v_addc_co_u32      v4, vcc, 0, v4, vcc
/*0000000003a8: dc400000 03000003*/ flat_load_ubyte v3, v[3:4]
/*0000000003b0: d2860007 00013411*/ v_mul_hi_u32    v7, s17, 26
/*0000000003b8: bf8c0070         */ s_waitcnt       vmcnt(0) & lgkmcnt(0)
/*0000000003bc: 34060d03         */ v_sub_co_u32       v3, vcc, v3, v6
/*0000000003c0: d1c90003 02210103*/ v_bfe_i32       v3, v3, 0, 8
/*0000000003c8: 320606b4         */ v_add_co_u32       v3, vcc, 52, v3
/*0000000003cc: d2870004 00020503*/ v_mul_hi_i32    v4, v3, v2
/*0000000003d4: 2014089f         */ v_lshrrev_b32   v10, 31, v4
/*0000000003d8: 20080883         */ v_lshrrev_b32   v4, 3, v4
/*0000000003dc: 32081504         */ v_add_co_u32       v4, vcc, v4, v10
/*0000000003e0: d2850004 00013504*/ v_mul_lo_u32    v4, v4, 26
/*0000000003e8: 7e140205         */ v_mov_b32       v10, s5
/*0000000003ec: 36060704         */ v_subrev_co_u32    v3, vcc, v4, v3
/*0000000003f0: 3208140a         */ v_add_co_u32       v4, vcc, s10, v10
/*0000000003f4: d1c90003 02210103*/ v_bfe_i32       v3, v3, 0, 8
/*0000000003fc: 380e0f08         */ v_addc_co_u32      v7, vcc, v8, v7, vcc
/*000000000400: 2214069f         */ v_ashrrev_i32   v10, 31, v3
/*000000000404: 32060704         */ v_add_co_u32       v3, vcc, v4, v3
/*000000000408: 38081507         */ v_addc_co_u32      v4, vcc, v7, v10, vcc
/*00000000040c: dc440000 03000003*/ flat_load_sbyte v3, v[3:4]
/*000000000414: bf8c0070         */ s_waitcnt       vmcnt(0) & lgkmcnt(0)
/*000000000418: 32060d03         */ v_add_co_u32       v3, vcc, v3, v6
/*00000000041c: 320606b4         */ v_add_co_u32       v3, vcc, 52, v3
/*000000000420: d2870002 00020503*/ v_mul_hi_i32    v2, v3, v2
/*000000000428: 2008049f         */ v_lshrrev_b32   v4, 31, v2
/*00000000042c: 20040483         */ v_lshrrev_b32   v2, 3, v2
/*000000000430: 32040902         */ v_add_co_u32       v2, vcc, v2, v4
/*000000000434: d2850002 00013502*/ v_mul_lo_u32    v2, v2, 26
/*00000000043c: 36040702         */ v_subrev_co_u32    v2, vcc, v2, v3
/*000000000440: d1c90002 02210102*/ v_bfe_i32       v2, v2, 0, 8
/*000000000448: 2206049f         */ v_ashrrev_i32   v3, 31, v2
/*00000000044c: 32040505         */ v_add_co_u32       v2, vcc, v5, v2
/*000000000450: 38060709         */ v_addc_co_u32      v3, vcc, v9, v3, vcc
/*000000000454: 320404ff 000001a0*/ v_add_co_u32       v2, vcc, 0x1a0, v2
/*00000000045c: 38060680         */ v_addc_co_u32      v3, vcc, 0, v3, vcc
/*000000000460: dc400000 02000002*/ flat_load_ubyte v2, v[2:3]
/*000000000468: bf8c0070         */ s_waitcnt       vmcnt(0) & lgkmcnt(0)
/*00000000046c: 34040d02         */ v_sub_co_u32       v2, vcc, v2, v6
/*000000000470: bf82001a         */ s_branch        .L1244_0
.L1140_0:
/*000000000474: d1c90003 02210103*/ v_bfe_i32       v3, v3, 0, 8
/*00000000047c: 320606b4         */ v_add_co_u32       v3, vcc, 52, v3
/*000000000480: d2870002 00020503*/ v_mul_hi_i32    v2, v3, v2
/*000000000488: 92059a11         */ s_mul_i32       s5, s17, 26
/*00000000048c: 7e0a0205         */ v_mov_b32       v5, s5
/*000000000490: 7e0c020b         */ v_mov_b32       v6, s11
/*000000000494: 2008049f         */ v_lshrrev_b32   v4, 31, v2
/*000000000498: 20040483         */ v_lshrrev_b32   v2, 3, v2
/*00000000049c: 32040902         */ v_add_co_u32       v2, vcc, v2, v4
/*0000000004a0: d2850002 00013502*/ v_mul_lo_u32    v2, v2, 26
/*0000000004a8: d2860004 00013411*/ v_mul_hi_u32    v4, s17, 26
/*0000000004b0: 36040702         */ v_subrev_co_u32    v2, vcc, v2, v3
/*0000000004b4: 320a0a0a         */ v_add_co_u32       v5, vcc, s10, v5
/*0000000004b8: d1c90002 02210102*/ v_bfe_i32       v2, v2, 0, 8
/*0000000004c0: 38080d04         */ v_addc_co_u32      v4, vcc, v4, v6, vcc
/*0000000004c4: 2206049f         */ v_ashrrev_i32   v3, 31, v2
/*0000000004c8: 32040505         */ v_add_co_u32       v2, vcc, v5, v2
/*0000000004cc: 38060704         */ v_addc_co_u32      v3, vcc, v4, v3, vcc
/*0000000004d0: dc400000 02000002*/ flat_load_ubyte v2, v[2:3]
/*0000000004d8: bf8c0070         */ s_waitcnt       vmcnt(0) & lgkmcnt(0)
.L1244_0:
/*0000000004dc: 7e0602ff 000002a4*/ v_mov_b32       v3, 0x2a4
/*0000000004e4: 0c060608         */ v_mul_i32_i24   v3, s8, v3
/*0000000004e8: d1c20003 040d3402*/ v_mad_i32_i24   v3, s2, 26, v3
/*0000000004f0: 32060103         */ v_add_co_u32       v3, vcc, v3, v0
/*0000000004f4: d2850003 00000703*/ v_mul_lo_u32    v3, v3, s3
/*0000000004fc: 7e08020d         */ v_mov_b32       v4, s13
/*000000000500: d1c90002 02210102*/ v_bfe_i32       v2, v2, 0, 8
/*000000000508: 7e0c02ff 4ec4ec4f*/ v_mov_b32       v6, 0x4ec4ec4f
/*000000000510: 320a060c         */ v_add_co_u32       v5, vcc, s12, v3
/*000000000514: 38080880         */ v_addc_co_u32      v4, vcc, 0, v4, vcc
/*000000000518: 32040409         */ v_add_co_u32       v2, vcc, s9, v2
/*00000000051c: d2870003 00020d02*/ v_mul_hi_i32    v3, v2, v6
/*000000000524: 92039a13         */ s_mul_i32       s3, s19, 26
/*000000000528: 7e100203         */ v_mov_b32       v8, s3
/*00000000052c: 8003ff0a 000001a0*/ s_add_u32       s3, s10, 0x1a0
/*000000000534: 200e069f         */ v_lshrrev_b32   v7, 31, v3
/*000000000538: 20060683         */ v_lshrrev_b32   v3, 3, v3
/*00000000053c: 32060f03         */ v_add_co_u32       v3, vcc, v3, v7
/*000000000540: d2850003 00013503*/ v_mul_lo_u32    v3, v3, 26
/*000000000548: d2860007 00013413*/ v_mul_hi_u32    v7, s19, 26
/*000000000550: 8205800b         */ s_addc_u32      s5, s11, 0
/*000000000554: 7e120205         */ v_mov_b32       v9, s5
/*000000000558: 36040503         */ v_subrev_co_u32    v2, vcc, v3, v2
/*00000000055c: 32101003         */ v_add_co_u32       v8, vcc, s3, v8
/*000000000560: d1c90002 02210102*/ v_bfe_i32       v2, v2, 0, 8
/*000000000568: 380e1307         */ v_addc_co_u32      v7, vcc, v7, v9, vcc
/*00000000056c: 2206049f         */ v_ashrrev_i32   v3, 31, v2
/*000000000570: 32040508         */ v_add_co_u32       v2, vcc, v8, v2
/*000000000574: 38060707         */ v_addc_co_u32      v3, vcc, v7, v3, vcc
/*000000000578: dc400000 02000002*/ flat_load_ubyte v2, v[2:3]
/*000000000580: d2860007 00013404*/ v_mul_hi_u32    v7, s4, 26
/*000000000588: 92049a04         */ s_mul_i32       s4, s4, 26
/*00000000058c: d1c90001 02210101*/ v_bfe_i32       v1, v1, 0, 8
/*000000000594: bf8c0070         */ s_waitcnt       vmcnt(0) & lgkmcnt(0)
/*000000000598: 36040408         */ v_subrev_co_u32    v2, vcc, s8, v2
/*00000000059c: d1c90002 02210102*/ v_bfe_i32       v2, v2, 0, 8
/*0000000005a4: 32040407         */ v_add_co_u32       v2, vcc, s7, v2
/*0000000005a8: d2870003 00020d02*/ v_mul_hi_i32    v3, v2, v6
/*0000000005b0: 2010069f         */ v_lshrrev_b32   v8, 31, v3
/*0000000005b4: 20060683         */ v_lshrrev_b32   v3, 3, v3
/*0000000005b8: 32061103         */ v_add_co_u32       v3, vcc, v3, v8
/*0000000005bc: d2850003 00013503*/ v_mul_lo_u32    v3, v3, 26
/*0000000005c4: 7e100204         */ v_mov_b32       v8, s4
/*0000000005c8: 36040503         */ v_subrev_co_u32    v2, vcc, v3, v2
/*0000000005cc: 32061003         */ v_add_co_u32       v3, vcc, s3, v8
/*0000000005d0: d1c90002 02210102*/ v_bfe_i32       v2, v2, 0, 8
/*0000000005d8: 380e0f09         */ v_addc_co_u32      v7, vcc, v9, v7, vcc
/*0000000005dc: 2210049f         */ v_ashrrev_i32   v8, 31, v2
/*0000000005e0: 32040503         */ v_add_co_u32       v2, vcc, v3, v2
/*0000000005e4: 38061107         */ v_addc_co_u32      v3, vcc, v7, v8, vcc
/*0000000005e8: dc400000 02000002*/ flat_load_ubyte v2, v[2:3]
/*0000000005f0: d2860007 00013406*/ v_mul_hi_u32    v7, s6, 26
/*0000000005f8: bf8c0070         */ s_waitcnt       vmcnt(0) & lgkmcnt(0)
/*0000000005fc: 36040402         */ v_subrev_co_u32    v2, vcc, s2, v2
/*000000000600: d1c90002 02210102*/ v_bfe_i32       v2, v2, 0, 8
/*000000000608: 32040102         */ v_add_co_u32       v2, vcc, v2, v0
/*00000000060c: 320404b4         */ v_add_co_u32       v2, vcc, 52, v2
/*000000000610: d2870003 00020d02*/ v_mul_hi_i32    v3, v2, v6
/*000000000618: 92029a06         */ s_mul_i32       s2, s6, 26
/*00000000061c: 2010069f         */ v_lshrrev_b32   v8, 31, v3
/*000000000620: 20060683         */ v_lshrrev_b32   v3, 3, v3
/*000000000624: 32061103         */ v_add_co_u32       v3, vcc, v3, v8
/*000000000628: d2850003 00013503*/ v_mul_lo_u32    v3, v3, 26
/*000000000630: 7e100202         */ v_mov_b32       v8, s2
/*000000000634: 36040503         */ v_subrev_co_u32    v2, vcc, v3, v2
/*000000000638: 32061003         */ v_add_co_u32       v3, vcc, s3, v8
/*00000000063c: d1c90002 02210102*/ v_bfe_i32       v2, v2, 0, 8
/*000000000644: 380e0f09         */ v_addc_co_u32      v7, vcc, v9, v7, vcc
/*000000000648: 2210049f         */ v_ashrrev_i32   v8, 31, v2
/*00000000064c: 32040503         */ v_add_co_u32       v2, vcc, v3, v2
/*000000000650: 38061107         */ v_addc_co_u32      v3, vcc, v7, v8, vcc
/*000000000654: dc400000 02000002*/ flat_load_ubyte v2, v[2:3]
/*00000000065c: bf8c0070         */ s_waitcnt       vmcnt(0) & lgkmcnt(0)
/*000000000660: 34000102         */ v_sub_co_u32       v0, vcc, v2, v0
/*000000000664: d1c90000 02210100*/ v_bfe_i32       v0, v0, 0, 8
/*00000000066c: 320000b4         */ v_add_co_u32       v0, vcc, 52, v0
/*000000000670: d2870002 00020d00*/ v_mul_hi_i32    v2, v0, v6
/*000000000678: 2006049f         */ v_lshrrev_b32   v3, 31, v2
/*00000000067c: 20040483         */ v_lshrrev_b32   v2, 3, v2
/*000000000680: 32040702         */ v_add_co_u32       v2, vcc, v2, v3
/*000000000684: d2850002 00013502*/ v_mul_lo_u32    v2, v2, 26
/*00000000068c: 2206029f         */ v_ashrrev_i32   v3, 31, v1
/*000000000690: 36040102         */ v_subrev_co_u32    v2, vcc, v2, v0
/*000000000694: 32000b01         */ v_add_co_u32       v0, vcc, v1, v5
/*000000000698: 38020704         */ v_addc_co_u32      v1, vcc, v4, v3, vcc
/*00000000069c: dc600000 00000200*/ flat_store_byte v[0:1], v2
/*0000000006a4: bf8c0070         */ s_waitcnt       vmcnt(0) & lgkmcnt(0)
.L1704_0:
/*0000000006a8: 87fe007e         */ s_or_b64        exec, exec, s[0:1]
/*0000000006ac: bf810000         */ s_endpgm
.ends

.endif
.endif
